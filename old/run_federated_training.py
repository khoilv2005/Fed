import torch
import torch.nn as nn
import torch.multiprocessing as mp
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import matplotlib.pyplot as plt
import os
import logging
import pickle
import json
import copy
from collections import OrderedDict
from typing import List, Dict, Tuple
from datetime import datetime
from tqdm.auto import tqdm
import time

# === TH√äM TH∆Ø VI·ªÜN CHO BI·ªÇU ƒê·ªí V√Ä K·∫æT QU·∫¢ ===
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, 
    classification_report, 
    precision_recall_fscore_support
)
import pandas as pd
# ============================================

# Import t·ª´ 2 file .py kia
try:
    from old.Fed import FederatedServer, FederatedClient
    from old.model import CNN_GRU_Model, build_cnn_gru_model
except ImportError as e:
    print("L·ªñI: Kh√¥ng t√¨m th·∫•y 'Fed.py' ho·∫∑c 'model.py'.")
    print(f"Chi ti·∫øt: {e}")
    print("H√£y ƒë·∫£m b·∫£o c·∫£ 3 file (.py) ƒë·ªÅu n·∫±m trong c√πng m·ªôt th∆∞ m·ª•c.")
    # ƒê·ªãnh nghƒ©a t·∫°m th·ªùi ƒë·ªÉ Colab kh√¥ng b√°o l·ªói ngay
    class FederatedClient: pass
    class FederatedServer: pass
    class CNN_GRU_Model(nn.Module): pass
    def build_cnn_gru_model(shape, classes): pass
    # Code s·∫Ω crash sau ƒë√≥, nh∆∞ng ƒë√¢y l√† ƒë·ªÉ debug import
    
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# üí° B∆Ø·ªöC 1: C·∫§U H√åNH CH√çNH üí°
# ============================================================================

CONFIG = {
    # ‚¨áÔ∏è CH·ªàNH ƒê∆Ø·ªúNG D·∫™N N√ÄY (TR√äN COLAB C·∫¶N MOUNT DRIVE TR∆Ø·ªöC) ‚¨áÔ∏è
    'data_dir': '/content/drive/MyDrive/Fed-Data/5-Client',
    'output_dir': '/content/drive/MyDrive/Fed-Data/5-Client/Results', # L∆∞u k·∫øt qu·∫£
    
    'num_clients': 5,

    # Model params (s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông ph√°t hi·ªán t·ª´ data)
    'input_shape': None,  # T·ª± ƒë·ªông ph√°t hi·ªán
    'num_classes': None,  # T·ª± ƒë·ªông ph√°t hi·ªán

    # Training params
    'algorithm': 'fedprox',     # 'fedavg' ho·∫∑c 'fedprox'
    'num_rounds': 4,            # 4 V√≤ng
    'local_epochs': 1,          # 1 Epoch/V√≤ng
    'learning_rate': 0.001,
    'batch_size': 2048,         # Batch size l·ªõn (GPU T4 15GB ch·∫°y t·ªët)
    'client_fraction': 1.0,     # T·ªâ l·ªá clients tham gia m·ªói round

    # FedProx specific
    'mu': 0.01,  # Proximal term coefficient

    # Device - Lu√¥n ∆∞u ti√™n GPU
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'force_gpu': True,  # Set False n·∫øu mu·ªën cho ph√©p ch·∫°y tr√™n CPU

    # Multiprocessing
    'use_multiprocessing': True,  # ‚úÖ ƒê·∫∑t True ƒë·ªÉ ch·∫°y song song
    'num_processes': 2,           # S·ªë processes (Colab free ch·ªâ c√≥ 2 CPU cores)

    # Visualization
    'eval_every': 1,  # ƒê√°nh gi√° sau m·ªói round
}

# === T·∫†O TH∆Ø M·ª§C OUTPUT ===
TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
OUTPUT_DIR = os.path.join(CONFIG['output_dir'], f"run_{TIMESTAMP}_{CONFIG['algorithm']}")
os.makedirs(OUTPUT_DIR, exist_ok=True)
CONFIG['output_dir'] = OUTPUT_DIR # C·∫≠p nh·∫≠t config v·ªõi ƒë∆∞·ªùng d·∫´n m·ªõi

# ============================================================================
# üí° B∆Ø·ªöC 2: H√ÄM KI·ªÇM TRA GPU üí°
# ============================================================================

def check_and_setup_gpu(config: Dict) -> str:
    """
    Ki·ªÉm tra GPU v√† tr·∫£ v·ªÅ torch.device ph√π h·ª£p.
    """
    logger.info("\n" + "="*80)
    logger.info("üîß KI·ªÇM TRA THI·∫æT B·ªä GPU/CPU")
    logger.info("="*80)

    cuda_available = torch.cuda.is_available()
    logger.info(f"   - CUDA kh·∫£ d·ª•ng: {cuda_available}")

    if cuda_available:
        device = torch.device('cuda')
        logger.info(f"   - Phi√™n b·∫£n CUDA: {torch.version.cuda}")
        logger.info(f"   - S·ªë l∆∞·ª£ng GPU: {torch.cuda.device_count()}")

        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            logger.info(f"\n   ‚û§ GPU {i}:")
            logger.info(f" ¬† ¬† ¬†- T√™n: {torch.cuda.get_device_name(i)}")
            logger.info(f" ¬† ¬† ¬†- B·ªô nh·ªõ: {props.total_memory / 1024**3:.2f} GB")
            logger.info(f" ¬† ¬† ¬†- Compute capability: {props.major}.{props.minor}")
        
        logger.info(f"\n‚úÖ S·ª≠ d·ª•ng thi·∫øt b·ªã: {torch.cuda.get_device_name(0)}")
    else:
        if config.get('force_gpu', False):
            logger.error("\n‚ùå L·ªñI: Kh√¥ng ph√°t hi·ªán GPU nh∆∞ng force_gpu=True")
            raise RuntimeError("Y√™u c·∫ßu GPU nh∆∞ng kh√¥ng c√≥ GPU kh·∫£ d·ª•ng.")
        else:
            device = torch.device('cpu')
            logger.warning(f"\n‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng c√≥ GPU, h·ªá th·ªëng s·∫Ω ch·∫°y tr√™n CPU (ch·∫≠m h∆°n).")

    logger.info("="*80)
    # Tr·∫£ v·ªÅ string, kh√¥ng ph·∫£i torch.device, ƒë·ªÉ d·ªÖ d√†ng serialize
    return 'cuda' if cuda_available else 'cpu'

# ============================================================================
# üí° B∆Ø·ªöC 3: H√ÄM T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN THAM S·ªê D·ªÆ LI·ªÜU üí°
# ============================================================================

def auto_detect_data_parameters(data_dir, num_clients):
    """
    T·ª± ƒë·ªông ph√°t hi·ªán input_shape v√† num_classes.
    """
    logger.info("\n" + "="*80)
    logger.info("üìÇ T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN THAM S·ªê D·ªÆ LI·ªÜU")
    logger.info("="*80)
    logger.info(f"‚Üí Th∆∞ m·ª•c d·ªØ li·ªáu: {data_dir}")
    logger.info(f"‚Üí S·ªë l∆∞·ª£ng client (d·ª± ki·∫øn): {num_clients}")

    try:
        all_labels = []
        data_stats = {}

        # L·∫•y k√≠ch th∆∞·ªõc input t·ª´ client_0
        client_0_path = os.path.join(data_dir, "client_0_data.npz")
        if not os.path.exists(client_0_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {client_0_path}")

        with np.load(client_0_path) as data:
            x_train_sample = data['X_train']
            input_features = x_train_sample.shape[1]
            input_shape = (input_features,)
            logger.info(f"\n‚úÖ Th√¥ng tin t·ª´ client 0:")
            logger.info(f"   - S·ªë ƒë·∫∑c tr∆∞ng (INPUT_FEATURES): {input_features}")
            logger.info(f"   - input_shape: {input_shape}")

        logger.info(f"\n‚Üí ƒêang qu√©t d·ªØ li·ªáu c·ªßa {num_clients} client ƒë·ªÉ th·ªëng k√™ nh√£n...")
        total_train = 0
        total_test = 0

        for i in range(num_clients):
            file_path = os.path.join(data_dir, f"client_{i}_data.npz")
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {file_path}")

            with np.load(file_path) as data:
                x_train = data['X_train']; y_train = data['y_train']
                x_test = data['X_test']; y_test = data['y_test']

                all_labels.append(y_train)
                all_labels.append(y_test) # Qu√©t c·∫£ nh√£n test
                
                unique_labels, counts = np.unique(y_train, return_counts=True)
                total_train += len(x_train)
                total_test += len(x_test)

                data_stats[i] = {
                    'train_samples': int(len(x_train)),
                    'test_samples': int(len(x_test)),
                    'unique_labels': int(len(unique_labels)),
                    'label_distribution': {str(k): int(v) for k, v in zip(unique_labels, counts)}
                }
                logger.info(f"   - Client {i}: {len(x_train):,} train, {len(x_test):,} test, {len(unique_labels)} nh√£n")

        combined_labels = np.concatenate(all_labels)
        num_classes = len(np.unique(combined_labels))

        logger.info("\nüìä T·ªïng h·ª£p to√†n b·ªô d·ªØ li·ªáu:")
        logger.info(f"   - S·ªë l·ªõp (num_classes): {num_classes}")
        logger.info(f"   - T·ªïng s·ªë m·∫´u train: {total_train:,}")
        logger.info(f"   - T·ªïng s·ªë m·∫´u test:  {total_test:,}")
        logger.info("="*80)

        return input_shape, num_classes, data_stats

    except FileNotFoundError as e:
        logger.error("\n" + "="*80 + f"\n‚ùå L·ªñI: KH√îNG T√åM TH·∫§Y T·ªÜP D·ªÆ LI·ªÜU\nƒê∆∞·ªùng d·∫´n: {e.filename}\n" + "="*80)
        raise
    except KeyError as e:
        logger.error("\n" + "="*80 + f"\n‚ùå L·ªñI: THI·∫æU KEY TRONG FILE .NPZ\nKey: {e}\n" + "="*80)
        raise

# ============================================================================
# üí° B∆Ø·ªöC 4: H√ÄM LOAD D·ªÆ LI·ªÜU üí°
# ============================================================================

class NumpyDataset(TensorDataset):
    """Dataset ti·ªán d·ª•ng ƒë·ªÉ wrap numpy array th√†nh TensorDataset."""
    def __init__(self, X, y):
        if len(X.shape) == 3:
            X = X.squeeze(-1)  # (N, F, 1) -> (N, F)

        X = X.astype(np.float32)
        X_tensor = torch.from_numpy(X)
        y_tensor = torch.from_numpy(y).long()
        super().__init__(X_tensor, y_tensor)


def load_federated_data(data_dir, num_clients, batch_size, device='cpu'):
    """
    Load d·ªØ li·ªáu federated cho t·∫•t c·∫£ client.
    """
    logger.info("\n" + "="*80)
    logger.info("üì• LOADING FEDERATED DATA")
    logger.info("="*80)
    logger.info(f"‚Üí Thi·∫øt b·ªã hi·ªán d√πng: {device}")
    logger.info(f"‚Üí S·ªë l∆∞·ª£ng client: {num_clients}\n")

    train_loaders = []
    test_loaders = []

    for client_id in range(num_clients):
        data_path = os.path.join(data_dir, f'client_{client_id}_data.npz')
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu c·ªßa client {client_id} t·∫°i: {data_path}")

        data = np.load(data_path)
        X_train = data['X_train']; y_train = data['y_train']
        X_test = data['X_test']; y_test = data['y_test']

        logger.info(f"   - Client {client_id}: X_train {X_train.shape}, X_test {X_test.shape}")

        train_dataset = NumpyDataset(X_train, y_train)
        test_dataset = NumpyDataset(X_test, y_test)

        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True, drop_last=False
        )
        test_loader = DataLoader(
            test_dataset, batch_size=batch_size*2, shuffle=False, drop_last=False # Batch size test l·ªõn h∆°n
        )
        train_loaders.append(train_loader)
        test_loaders.append(test_loader)

    logger.info(f"\n‚úÖ ƒê√£ load d·ªØ li·ªáu cho {num_clients} client.")
    logger.info("="*80)

    return train_loaders, test_loaders

# ============================================================================
# üí° B∆Ø·ªöC 5: H√ÄM KH·ªûI T·∫†O H·ªÜ TH·ªêNG üí°
# ============================================================================

def initialize_federated_system(
    config: Dict,
    train_loaders: List[DataLoader],
    test_loaders: List[DataLoader]
):
    """
    Kh·ªüi t·∫°o global model, clients, v√† server (ƒë√£ s·ª≠a l·ªói RAM)
    """
    logger.info("\n" + "="*80)
    logger.info("üèóÔ∏è  INITIALIZING FEDERATED SYSTEM")
    logger.info("="*80)
    
    input_shape = config['input_shape']
    num_classes = config['num_classes']
    device = config['device']
    num_clients = config['num_clients']

    # T·∫°o global model
    logger.info(f"\n‚Üí Kh·ªüi t·∫°o m√¥ h√¨nh to√†n c·ª•c (global model)...")
    logger.info(f"   - Input shape: {input_shape}")
    logger.info(f"   - S·ªë l·ªõp: {num_classes}")
    logger.info(f"   - Thi·∫øt b·ªã: {device}")

    global_model = build_cnn_gru_model(input_shape, num_classes)
    global_model = global_model.to(device)
    logger.info(f"   - M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang thi·∫øt b·ªã: {device}")

    if device == 'cuda':
        logger.info(f"   - X√°c nh·∫≠n tham s·ªë ƒë·∫ßu ti√™n c·ªßa m√¥ h√¨nh ƒëang ·ªü: {next(global_model.parameters()).device}")

    total_params = sum(p.numel() for p in global_model.parameters())
    trainable_params = sum(p.numel() for p in global_model.parameters() if p.requires_grad)
    logger.info(f"   - T·ªïng s·ªë tham s·ªë: {total_params:,}")
    logger.info(f"   - S·ªë tham s·ªë trainable: {trainable_params:,}")

    # T·∫°o clients (Ch·ªâ c·∫ßn thi·∫øt cho ch·∫ø ƒë·ªô Tu·∫ßn T·ª±)
    clients = []
    if not config['use_multiprocessing']:
        logger.info(f"\n‚Üí Kh·ªüi t·∫°o {num_clients} client (ch·∫ø ƒë·ªô tu·∫ßn t·ª±)...")
        for client_id in range(num_clients):
            client_model = CNN_GRU_Model(input_shape, num_classes)
            client_model.load_state_dict(global_model.state_dict())

            client = FederatedClient(
                client_id=client_id,
                model=client_model,
                train_loader=train_loaders[client_id],
                test_loader=test_loaders[client_id],
                device=device
            )
            clients.append(client)
            logger.info(f"   - Client {client_id}: kh·ªüi t·∫°o th√†nh c√¥ng tr√™n thi·∫øt b·ªã {device}")
    else:
        logger.info(f"\n‚Üí B·ªè qua kh·ªüi t·∫°o Client (ch·∫ø ƒë·ªô song song)...")
        
    
    logger.info("\n‚Üí G√°n danh s√°ch test loader cho server (tr√°nh l·ªói RAM)...")
    
    # T·∫°o server
    logger.info("\n‚Üí Kh·ªüi t·∫°o server...")
    server = FederatedServer(
        model=global_model,
        clients=clients, # List n√†y s·∫Ω r·ªóng n·∫øu d√πng multiprocessing
        client_test_loaders=test_loaders, # ‚úÖ S·ª¨A: D√πng list test loader
        device=device
    )

    logger.info("\n‚úÖ H·ªá th·ªëng Federated ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ho√†n ch·ªânh.")
    logger.info("="*80)

    return server, clients

# ============================================================================
# üí° B∆Ø·ªöC 6: C√ÅC H√ÄM H·ªñ TR·ª¢ MULTIPROCESSING üí°
# ============================================================================

# (C·∫ßn import l·∫°i b√™n trong worker)
def _client_training_worker(args_tuple):
    """
    H√†m worker (helper) ƒë·ªÉ ch·∫°y trong m·ªôt process ri√™ng bi·ªát.
    """
    # Import l·∫°i c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt cho process n√†y
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import numpy as np
    from collections import OrderedDict
    from tqdm.auto import tqdm as _tqdm
    import time as _time
    import os # Th√™m os
    
    # === B·∫ÆT ƒê·∫¶U ƒê·ªäNH NGHƒ®A L·∫†I (B·∫Øt bu·ªôc cho 'spawn') ===
    # (ƒê√¢y l√† b·∫£n copy-paste c·ªßa class model)
    class CNN_GRU_Model_Worker(nn.Module):
        def __init__(self, input_shape, num_classes=2):
            super(CNN_GRU_Model_Worker, self).__init__()
            if isinstance(input_shape, tuple): seq_length = input_shape[0]
            else: seq_length = input_shape
            self.input_shape = input_shape; self.num_classes = num_classes
            def conv_output_shape(L_in, kernel_size=1, stride=1, padding=0, dilation=1):
                if padding == 1 and kernel_size == 3: L_out_conv = L_in
                else: L_out_conv = (L_in + 2*padding - dilation*(kernel_size-1) - 1) // stride + 1
                return L_out_conv
            def pool_output_shape(L_in, kernel_size=2, stride=2, padding=0, dilation=1): return (L_in + 2*padding - dilation*(kernel_size-1) - 1) // stride + 1
            self.conv1 = nn.Conv1d(1, 64, 3, padding=1); self.bn1 = nn.BatchNorm1d(64); self.pool1 = nn.MaxPool1d(2, stride=2); self.dropout_cnn1 = nn.Dropout(0.2)
            self.conv2 = nn.Conv1d(64, 128, 3, padding=1); self.bn2 = nn.BatchNorm1d(128); self.pool2 = nn.MaxPool1d(2, stride=2); self.dropout_cnn2 = nn.Dropout(0.2)
            self.conv3 = nn.Conv1d(128, 256, 3, padding=1); self.bn3 = nn.BatchNorm1d(256); self.pool3 = nn.MaxPool1d(2, stride=2); self.dropout_cnn3 = nn.Dropout(0.3)
            cnn_output_length = seq_length
            cnn_output_length = pool_output_shape(conv_output_shape(cnn_output_length, kernel_size=3, padding=1))
            cnn_output_length = pool_output_shape(conv_output_shape(cnn_output_length, kernel_size=3, padding=1))
            cnn_output_length = pool_output_shape(conv_output_shape(cnn_output_length, kernel_size=3, padding=1))
            self.cnn_output_size = 256 * cnn_output_length
            self.gru1 = nn.GRU(1, 128, batch_first=True); self.gru2 = nn.GRU(128, 64, batch_first=True); self.gru_output_size = 64
            concat_size = self.cnn_output_size + self.gru_output_size
            self.dense1 = nn.Linear(concat_size, 256); self.bn_mlp1 = nn.BatchNorm1d(256); self.dropout1 = nn.Dropout(0.4)
            self.dense2 = nn.Linear(256, 128); self.bn_mlp2 = nn.BatchNorm1d(128); self.dropout2 = nn.Dropout(0.3)
            self.output = nn.Linear(128, num_classes); self.relu = nn.ReLU()
        
        def forward(self, x):
            if len(x.shape) == 2: x = x.unsqueeze(-1)
            batch_size = x.size(0); x_cnn = x.permute(0, 2, 1)
            x_cnn = self.dropout_cnn1(self.pool1(self.relu(self.bn1(self.conv1(x_cnn)))))
            x_cnn = self.dropout_cnn2(self.pool2(self.relu(self.bn2(self.conv2(x_cnn)))))
            x_cnn = self.dropout_cnn3(self.pool3(self.relu(self.bn3(self.conv3(x_cnn)))))
            cnn_output = x_cnn.view(batch_size, -1); x_gru = x; x_gru, _ = self.gru1(x_gru); x_gru, _ = self.gru2(x_gru)
            gru_output = x_gru[:, -1, :]; concatenated = torch.cat([cnn_output, gru_output], dim=1)
            x = self.dense1(concatenated); 
            if x.shape[0] > 1: x = self.bn_mlp1(x)
            x = self.relu(x); x = self.dropout1(x)
            x = self.dense2(x); 
            if x.shape[0] > 1: x = self.bn_mlp2(x)
            x = self.relu(x); x = self.dropout2(x)
            return self.output(x)

    class NumpyDataset_Worker(TensorDataset):
        def __init__(self, X, y):
            if len(X.shape) == 3: X = X.squeeze(-1)
            X = X.astype(np.float32)
            X_tensor = torch.from_numpy(X)
            y_tensor = torch.from_numpy(y).long()
            super().__init__(X_tensor, y_tensor)
    # === K·∫æT TH√öC ƒê·ªäNH NGHƒ®A L·∫†I ===
    
    try:
        # Gi·∫£i n√©n arguments
        (client_id, model_state_dict, client_data_path, device_id, 
         config) = args_tuple
        
        # L·∫•y config
        num_epochs = config['local_epochs']
        learning_rate = config['learning_rate']
        algorithm = config['algorithm']
        mu = config['mu']
        batch_size = config['batch_size']
        
        # Set device
        if device_id != 'cpu' and torch.cuda.is_available():
            device = torch.device(f'cuda:{device_id}')
        else:
            device = torch.device('cpu')
        
        # ‚úÖ S·ª¨A L·ªñI RAM: Worker t·ª± load data
        with np.load(client_data_path) as data:
            X_train = data['X_train']
            y_train = data['y_train']
            
        # T·∫°o DataLoader
        train_dataset = NumpyDataset_Worker(X_train, y_train)
        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True, drop_last=False
        )
        
        # T·∫°o model v√† load state
        model = CNN_GRU_Model_Worker(config['input_shape'], config['num_classes'])
        model.load_state_dict(model_state_dict)
        model = model.to(device)
        
        # Hu·∫•n luy·ªán
        model.train()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate) # D√πng Adam
        criterion = nn.CrossEntropyLoss()
        
        total_loss = 0.0
        total_samples = 0
        
        for epoch in range(num_epochs):
            epoch_loss = 0.0
            epoch_samples = 0
            
            # ƒê·∫∑t position=client_id ƒë·ªÉ c√°c thanh progress bar x·∫øp ch·ªìng l√™n nhau
            pbar = _tqdm(
                train_loader,
                desc=f"[Worker Client {client_id} (GPU {device_id})] Epoch {epoch+1}/{num_epochs}",
                unit="batch",
                leave=False,
                position=client_id 
            )

            for data, target in pbar:
                batch_start = _time.time()

                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                ce_loss = criterion(output, target)
                
                # FedProx proximal term
                if algorithm == 'fedprox' and model_state_dict is not None:
                    proximal_term = 0.0
                    # ‚úÖ S·ª¨A L·ªñI: D√πng named_parameters v√† so s√°nh v·ªõi state_dict
                    for name, param in model.named_parameters():
                        if param.requires_grad:
                            global_param = model_state_dict[name].to(device)
                            proximal_term += torch.sum((param - global_param) ** 2)
                    loss = ce_loss + (mu / 2) * proximal_term
                    prox_val = float(((mu / 2) * proximal_term).detach().cpu().item())
                else:
                    loss = ce_loss
                    prox_val = 0.0
                
                loss.backward()
                optimizer.step()
                
                batch_time = _time.time() - batch_start

                epoch_loss += ce_loss.item() * data.size(0)
                epoch_samples += data.size(0)

                pbar.set_postfix({
                    "ce": f"{ce_loss.item():.4f}",
                    "prox": f"{prox_val:.2e}",
                    "bt": f"{batch_time*1000:.0f}ms"
                })
            
            total_loss += epoch_loss
            total_samples += epoch_samples
        
        avg_loss = total_loss / max(1, total_samples)
        
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£ (chuy·ªÉn params v·ªÅ CPU)
        return {
            'client_id': client_id,
            'model_state_dict': {k: v.cpu() for k, v in model.state_dict().items()},
            'num_samples': len(X_train),
            'loss': avg_loss
        }
    
    except Exception as e:
        print(f"‚ùå L·ªói trong worker client {client_id}: {e}")
        import traceback
        traceback.print_exc()
        return None


def aggregate_models_fedavg_parallel(client_results: List[Dict]) -> OrderedDict:
    """
    ‚úÖ ƒê√É S·ª¨A L·ªñI: FedAvg aggregation t·ª´ client results (Fix l·ªói Dtype)
    (Ch·∫°y tr√™n CPU)
    """
    total_samples = sum(r['num_samples'] for r in client_results)
    
    aggregated_params = OrderedDict()
    first_state = client_results[0]['model_state_dict']
    
    for key in first_state.keys():
        aggregated_params[key] = torch.zeros_like(first_state[key])
    
    for result in client_results:
        weight = result['num_samples'] / max(1, total_samples)
        state_dict = result['model_state_dict']
        
        for key in aggregated_params.keys():
            param = state_dict[key]
            
            # Ch·ªâ aggregate c√°c tham s·ªë float
            if param.dtype in [torch.float32, torch.float64, torch.float16]:
                weight_tensor = torch.tensor(weight, dtype=param.dtype, device=param.device)
                aggregated_params[key] += weight_tensor * param
            else:
                # Gi·ªØ l·∫°i gi√° tr·ªã c·ªßa client ƒë·∫ßu ti√™n (v√≠ d·ª•: num_batches_tracked)
                if result['client_id'] == client_results[0]['client_id']:
                    aggregated_params[key] = param
    
    return aggregated_params


def train_round_multiprocessing(
    server, # D√πng ƒë·ªÉ set params
    config,
    # train_loaders, # KH√îNG D√ôNG N·ªÆA
    device='cuda'
):
    """
    ‚úÖ ƒê√É S·ª¨A L·ªñI: Train 1 round v·ªõi multiprocessing (Fix l·ªói RAM OOM + TypeError)
    """
    # L·∫•y global model state (tr√™n CPU)
    global_state_dict = {k: v.cpu() for k, v in server.get_global_params().items()}
    
    # Ph√¢n b·ªï GPU (n·∫øu c√≥)
    if device == 'cuda' and torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        device_ids = [i % num_gpus for i in range(config['num_clients'])]
        if num_gpus > 1:
            logger.info(f"   ‚Ä¢ Ph√¢n b·ªï {config['num_clients']} clients cho {num_gpus} GPUs (round-robin).")
            logger.info(f"   ‚Ä¢ GPU mapping: {device_ids}")
        else:
            logger.info(f"   ‚Ä¢ T·∫•t c·∫£ {config['num_clients']} clients s·∫Ω d√πng chung 1 GPU (cuda:0).")
    else:
        # N·∫øu ch·ªâ c√≥ 1 GPU ho·∫∑c CPU
        device_ids = ['cpu'] * config['num_clients']
        logger.info(f"   ‚Ä¢ T·∫•t c·∫£ {config['num_clients']} clients s·∫Ω ch·∫°y tr√™n CPU.")

    
    # Chu·∫©n b·ªã arguments cho m·ªói client
    args_list = []
    for client_id in range(config['num_clients']):
        client_data_path = os.path.join(config['data_dir'], f"client_{client_id}_data.npz")
        
        args_list.append(
            (
                client_id,
                global_state_dict,
                client_data_path, # ‚úÖ S·ª¨A L·ªñI RAM: Ch·ªâ truy·ªÅn ƒë∆∞·ªùng d·∫´n
                device_ids[client_id],
                config # Truy·ªÅn to√†n b·ªô config
            )
        )
    
    # Train song song
    logger.info(f"   ‚Ä¢ B·∫Øt ƒë·∫ßu train {config['num_clients']} clients song song v·ªõi {config['num_processes']} processes...")
    
    mp_context = mp.get_context('spawn') # 'spawn' l√† b·∫Øt bu·ªôc cho CUDA
    logger.info(f"   ‚Ä¢ ƒêang kh·ªüi t·∫°o process pool...")
    
    results = []
    # D√πng pool.map ƒë·ªÉ ch·∫°y song song
    with mp_context.Pool(processes=config['num_processes']) as pool:
        logger.info(f"   ‚Ä¢ Pool ƒë√£ ƒë∆∞·ª£c t·∫°o, b·∫Øt ƒë·∫ßu submit {len(args_list)} tasks...")
        
        # D√πng imap_unordered ƒë·ªÉ c√≥ progress bar
        pbar = tqdm(
            pool.imap_unordered(_client_training_worker, args_list),
            total=len(args_list),
            desc="üîÑ Clients Training (Parallel)",
            unit="client"
        )
        for res in pbar:
            results.append(res)
    
    logger.info(f"\n   ‚Ä¢ ƒê√£ nh·∫≠n k·∫øt qu·∫£ t·ª´ {len(results)} clients.")
    
    # L·ªçc c√°c k·∫øt qu·∫£ l·ªói (None)
    results = [r for r in results if r is not None]
    
    if len(results) == 0:
        raise RuntimeError("T·∫•t c·∫£ clients ƒë·ªÅu th·∫•t b·∫°i!")
    
    # Aggregate models (tr√™n CPU)
    logger.info(f"   ‚Ä¢ ƒêang aggregate models t·ª´ {len(results)} clients...")
    aggregated_params_cpu = aggregate_models_fedavg_parallel(results)
    
    # C·∫≠p nh·∫≠t global model (chuy·ªÉn params v·ªÅ l·∫°i GPU)
    aggregated_params_gpu = OrderedDict(
        (k, v.to(device)) for k, v in aggregated_params_cpu.items()
    )
    server.set_global_params(aggregated_params_gpu)
    
    # T√≠nh avg loss
    avg_loss = np.mean([r['loss'] for r in results])
    
    return {
        'train_loss': avg_loss,
        'num_clients': len(results)
    }

# ============================================================================
# üí° B∆Ø·ªöC 9: H√ÄM HU·∫§N LUY·ªÜN CH√çNH üí°
# ============================================================================

def train_federated(server, config, train_loaders=None):
    """
    ƒêi·ªÅu ph·ªëi qu√° tr√¨nh hu·∫•n luy·ªán (ch·ªçn tu·∫ßn t·ª± ho·∫∑c song song)
    """
    logger.info("\n" + "="*80)
    logger.info("üöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN FEDERATED")
    logger.info("="*80)

    algorithm = config['algorithm']
    num_rounds = config['num_rounds']
    local_epochs = config['local_epochs']
    learning_rate = config['learning_rate']
    client_fraction = config['client_fraction']
    eval_every = config['eval_every']
    device = config['device']
    use_multiprocessing = config.get('use_multiprocessing', False)
    
    history = server.history # L·∫•y history t·ª´ server

    # In C·∫•u h√¨nh
    logger.info(f"\nüìã C·∫•u h√¨nh hu·∫•n luy·ªán:")
    logger.info(f"   - Thu·∫≠t to√°n: {algorithm.upper()}")
    logger.info(f"   - S·ªë round: {num_rounds}")
    logger.info(f"   - S·ªë epoch local: {local_epochs}")
    logger.info(f"   - Learning rate: {learning_rate}")
    logger.info(f"   - Batch size: {config['batch_size']}")
    logger.info(f"   - T·ªâ l·ªá client m·ªói round: {client_fraction}")
    logger.info(f"   - Thi·∫øt b·ªã: {device}")
    logger.info(f"   - Ch·∫°y song song (Multiprocessing): {use_multiprocessing}")
    if use_multiprocessing:
        logger.info(f"   - S·ªë Processes: {config['num_processes']}")
    if algorithm == 'fedprox':
        logger.info(f"   - Mu (proximal term): {config['mu']}")
    
    # ƒê√°nh gi√° ban ƒë·∫ßu (Round 0)
    if eval_every > 0:
        logger.info("\nüìä ƒê√°nh gi√° m√¥ h√¨nh to√†n c·ª•c (ch∆∞a hu·∫•n luy·ªán)...")
        eval_result = server.evaluate_global()
        history['train_loss'].append(None) # Ch∆∞a train
        history['test_accuracy'].append(eval_result['accuracy'])
        history['test_loss'].append(eval_result['loss'])
        logger.info(f"‚úÖ Round 0 (Init): Test Acc: {eval_result['accuracy']*100:.2f}% | Test Loss: {eval_result['loss']:.4f}")

    # === B·∫ÆT ƒê·∫¶U C√ÅC V√íNG HU·∫§N LUY·ªÜN ===
    round_iter = tqdm(
        range(num_rounds),
        desc="Global Rounds",
        unit="round"
    )

    for round_idx in round_iter:
        logger.info(f"\n{'='*60}")
        logger.info(f"üìç ROUND {round_idx+1}/{num_rounds}")
        logger.info(f"{'='*60}")
        
        # Ch·ªçn ch·∫ø ƒë·ªô ch·∫°y (Song song ho·∫∑c Tu·∫ßn t·ª±)
        if use_multiprocessing:
            # ===== CH·∫†Y SONG SONG (MULTIPROCESSING) =====
            logger.info("\nüî• Ch·∫ø ƒë·ªô: MULTIPROCESSING - Clients ch·∫°y song song")
            
            # C·∫≠p nh·∫≠t config cho worker
            worker_config = config.copy()
            worker_config['local_epochs'] = local_epochs
            worker_config['learning_rate'] = learning_rate
            worker_config['algorithm'] = algorithm
            worker_config['mu'] = config.get('mu', 0.01)

            # ‚úÖ S·ª¨A L·ªñI TypeError: X√≥a c√°c keyword arguments kh√¥ng h·ª£p l·ªá
            round_result = train_round_multiprocessing(
                server=server,
                config=worker_config,
                # train_loaders=train_loaders, # <-- ƒê√É X√ìA (G√¢y l·ªói)
                device=device
            )
        
        else:
            # ===== CH·∫†Y TU·∫¶N T·ª∞ (SEQUENTIAL) =====
            logger.info("\nüìù Ch·∫ø ƒë·ªô: SEQUENTIAL - Clients ch·∫°y l·∫ßn l∆∞·ª£t (ch·∫≠m)...")
            if algorithm == 'fedavg':
                round_result = server.train_round_fedavg(
                    num_epochs=local_epochs,
                    learning_rate=learning_rate,
                    client_fraction=client_fraction,
                    verbose=1 # B·∫≠t verbose cho client
                )
            elif algorithm == 'fedprox':
                round_result = server.train_round_fedprox(
                    num_epochs=local_epochs,
                    mu=config['mu'],
                    learning_rate=learning_rate,
                    client_fraction=client_fraction,
                    verbose=1 # B·∫≠t verbose cho client
                )
            else:
                raise ValueError(f"Thu·∫≠t to√°n kh√¥ng h·ªó tr·ª£: {algorithm}")

        # ƒê√°nh gi√° sau m·ªói v√≤ng
        if (round_idx + 1) % eval_every == 0:
            logger.info(f"\nüìä ƒêang ƒë√°nh gi√° m√¥ h√¨nh to√†n c·ª•c tr√™n test set...")
            eval_result = server.evaluate_global()

            history['train_loss'].append(round_result['train_loss'])
            history['test_accuracy'].append(eval_result['accuracy'])
            history['test_loss'].append(eval_result['loss'])

            logger.info(f"\n‚úÖ Round {round_idx+1}/{num_rounds} Summary:")
            logger.info(f"   ‚Ä¢ Train Loss (Avg): {round_result['train_loss']:.4f}")
            logger.info(f"   ‚Ä¢ Test Accuracy: {eval_result['accuracy']*100:.2f}%")
            logger.info(f"   ‚Ä¢ Test Loss: {eval_result['loss']:.4f}")
            
            round_iter.set_postfix({
                "algo": algorithm,
                "train_loss": f"{round_result['train_loss']:.4f}",
                "test_acc": f"{eval_result['accuracy']*100:.2f}%"
            })

    if history['test_accuracy']:
        logger.info(f"\n‚úÖ Hu·∫•n luy·ªán {algorithm.upper()} ho√†n t·∫•t.")
        logger.info(f"   ‚Üí ƒê·ªô ch√≠nh x√°c cu·ªëi c√πng tr√™n test: {history['test_accuracy'][-1]*100:.2f}%")
    else:
        logger.info("\n‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ test n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")

    return history

# ============================================================================
# üí° B∆Ø·ªöC 10: H√ÄM V·∫º BI·ªÇU ƒê·ªí & L∆ØU K·∫æT QU·∫¢ üí°
# ============================================================================

def plot_training_history(history, save_path):
    """
    V·∫Ω bi·ªÉu ƒë·ªì train_loss, test_loss v√† test_accuracy theo round.
    """
    logger.info("\n" + "="*80)
    logger.info("üìä ƒêANG V·∫º BI·ªÇU ƒê·ªí K·∫æT QU·∫¢ HU·∫§N LUY·ªÜN")
    logger.info("="*80)

    try:
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))
        
        # L·∫•y s·ªë v√≤ng (rounds), bao g·ªìm c·∫£ round 0
        rounds = range(len(history['test_loss'])) 
        train_loss = history['train_loss'] # train_loss[0] l√† None
        test_loss = history['test_loss']
        test_acc = history['test_accuracy']

        # Loss
        ax1 = axes[0]
        # B·ªè qua ƒëi·ªÉm None ƒë·∫ßu ti√™n c·ªßa train_loss
        ax1.plot(rounds[1:], train_loss[1:], label='Train Loss (Trung b√¨nh Client)', marker='o', linewidth=2)
        ax1.plot(rounds, test_loss, label='Test Loss (To√†n c·ª•c)', marker='s', linewidth=2)
        ax1.set_xlabel('Round', fontweight='bold')
        ax1.set_ylabel('Loss', fontweight='bold')
        ax1.set_title('Train Loss & Test Loss', fontweight='bold', fontsize=14)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_xticks(rounds)

        # Accuracy
        ax2 = axes[1]
        test_acc_pct = [acc * 100 for acc in test_acc]
        ax2.plot(rounds, test_acc_pct, label='Test Accuracy (%)', marker='o', linewidth=2, color='green')
        ax2.set_xlabel('Round', fontweight='bold')
        ax2.set_ylabel('Accuracy (%)', fontweight='bold')
        ax2.set_title('ƒê·ªô ch√≠nh x√°c tr√™n Test Set To√†n c·ª•c', fontweight='bold', fontsize=14)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 100])
        ax2.set_xticks(rounds)

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        logger.info(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì l·ªãch s·ª≠ hu·∫•n luy·ªán t·∫°i: {save_path}")
        plt.show() # Hi·ªÉn th·ªã plot trong notebook
    
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    finally:
        plt.close() # ƒê·∫£m b·∫£o ƒë√≥ng plot
        logger.info("="*80)


def evaluate_and_save_results(server, history, config, output_dir, data_stats, training_duration, start_time, end_time):
    """
    ƒê√°nh gi√° cu·ªëi c√πng, l∆∞u model, history, config v√† t·∫°o c√°c b√°o c√°o.
    """
    logger.info("\n" + "="*80)
    logger.info("üíæ B∆Ø·ªöC 9 & 10: ƒê√ÅNH GI√Å CU·ªêI C√ôNG V√Ä L∆ØU K·∫æT QU·∫¢")
    logger.info("="*80)
    
    device = config['device']

    # 1. L∆∞u Model
    model_path = os.path.join(output_dir, 'global_model.pth')
    torch.save(server.global_model.state_dict(), model_path)
    logger.info(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh to√†n c·ª•c: {model_path}")

    # 2. L∆∞u History
    history_path = os.path.join(output_dir, 'training_history.pkl')
    with open(history_path, 'wb') as f:
        pickle.dump(history, f)
    logger.info(f"‚úÖ ƒê√£ l∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán: {history_path}")

    # 3. L∆∞u Config
    config_path = os.path.join(output_dir, 'config.json')
    config_to_save = config.copy()
    config_to_save['device'] = str(config['device'])
    config_to_save['input_shape'] = str(config['input_shape']) # Chuy·ªÉn tuple sang str
    with open(config_path, 'w') as f:
        json.dump(config_to_save, f, indent=2)
    logger.info(f"‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh: {config_path}")

    # 4. L∆∞u Th·ªëng k√™ D·ªØ li·ªáu
    stats_path = os.path.join(output_dir, 'data_statistics.json')
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(data_stats, f, indent=2, ensure_ascii=False)
    logger.info(f"‚úÖ ƒê√£ l∆∞u th·ªëng k√™ d·ªØ li·ªáu: {stats_path}")

    # 5. V·∫Ω Bi·ªÉu ƒë·ªì
    plot_path = os.path.join(output_dir, 'training_history.png')
    plot_training_history(history, plot_path)
    
    # 6. ƒê√°nh gi√° cu·ªëi c√πng (L·∫•y d·ª± ƒëo√°n)
    logger.info("\n‚Üí ƒêang t·∫°o d·ª± ƒëo√°n (predictions) tr√™n Test Set to√†n c·ª•c...")
    all_y_true = []
    all_y_pred = []
    server.global_model.eval()
    
    # D√πng list test loader t·ª´ server
    pbar_predict = tqdm(
        server.client_test_loaders,
        desc="[Predict] L·∫•y d·ª± ƒëo√°n t·ª´ Test Set",
        unit="loader",
        leave=False
    )

    with torch.no_grad():
        for loader in pbar_predict: 
            for data, target in loader:
                data, target = data.to(device), target.to(device)
                output = server.global_model(data)
                pred = output.argmax(dim=1)
                
                all_y_true.append(target.cpu().numpy())
                all_y_pred.append(pred.cpu().numpy())
                
    y_true = np.concatenate(all_y_true)
    y_pred = np.concatenate(all_y_pred)
    logger.info("‚úÖ ƒê√£ t·∫°o d·ª± ƒëo√°n xong.")

    # 7. In v√† L∆∞u B√°o c√°o Ph√¢n lo·∫°i
    logger.info("\n" + "="*80)
    logger.info("üìÑ CLASSIFICATION REPORT")
    logger.info("="*80)
    class_labels = [str(i) for i in range(config['num_classes'])]
    report = classification_report(
        y_true, 
        y_pred, 
        labels=range(config['num_classes']),
        target_names=class_labels,
        zero_division=0,
        digits=4
    )
    print(report) # In ra m√†n h√¨nh
    
    report_path = os.path.join(output_dir, "classification_report.txt")
    with open(report_path, 'w') as f:
        f.write("CLASSIFICATION REPORT\n" + "="*80 + "\n\n" + report)
    logger.info(f"\nüíæ ƒê√£ l∆∞u report: {report_path}")

    # 8. V·∫Ω v√† L∆∞u Ma tr·∫≠n Nh·∫ßm l·∫´n
    logger.info("\n‚Üí ƒêang t·∫°o ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)...")
    cm = confusion_matrix(y_true, y_pred, labels=range(config['num_classes']))
    
    show_labels = (config['num_classes'] <= 40)
    fig_size = max(12, config['num_classes'] * 0.4)
    plt.figure(figsize=(fig_size, fig_size * 0.8))
    
    sns.heatmap(
        cm, 
        annot=show_labels, 
        fmt='d', 
        cmap='Blues',
        cbar=True,
        xticklabels=class_labels if show_labels else False,
        yticklabels=class_labels if show_labels else False
    )
    
    final_test_accuracy = history['test_accuracy'][-1]
    
    plt.title(f'Confusion Matrix - Final Global Model\n'
              f'Test Accuracy: {final_test_accuracy:.4f} ({final_test_accuracy*100:.2f}%)',
              fontsize=14, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    
    if show_labels:
        plt.xticks(rotation=90); plt.yticks(rotation=0)
    
    plt.tight_layout()
    cm_path = os.path.join(output_dir, "confusion_matrix.png")
    plt.savefig(cm_path, dpi=300, bbox_inches='tight')
    logger.info(f"‚úÖ ƒê√£ l∆∞u confusion matrix: {cm_path}")
    plt.show()
    plt.close()

    # 9. L∆∞u Metrics chi ti·∫øt (F1, Precision, Recall)
    logger.info("\n‚Üí ƒêang l∆∞u metrics chi ti·∫øt (F1, Precision, Recall)...")
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true, 
        y_pred, 
        labels=range(config['num_classes']),
        average=None,
        zero_division=0
    )
    detailed_metrics = {
        'class': class_labels,
        'precision': precision, 'recall': recall, 'f1_score': f1, 'support': support
    }
    df_metrics = pd.DataFrame(detailed_metrics)
    csv_path = os.path.join(output_dir, "detailed_metrics.csv")
    df_metrics.to_csv(csv_path, index=False)
    logger.info(f"‚úÖ ƒê√£ l∆∞u detailed metrics: {csv_path}")

    logger.info("\n" + "="*80)
    logger.info("üìä TOP 5 CLASSES PERFORMANCE:")
    logger.info("="*80)
    df_sorted = df_metrics.sort_values('f1_score', ascending=False)
    print("\nTop 5 Best Classes (by F1-score):")
    print(df_sorted.head(5).to_string(index=False))
    print("\nTop 5 Worst Classes (by F1-score):")
    print(df_sorted.tail(5).to_string(index=False))
    logger.info("="*80)
    
    # 10. T·∫°o Summary Report
    logger.info("\n" + "="*80)
    logger.info("üìù B∆Ø·ªöC 10: T·∫†O SUMMARY REPORT")
    logger.info("="*80)
    summary_path = os.path.join(OUTPUT_DIR, "SUMMARY_REPORT.txt")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n" + " "*20 + "FEDERATED LEARNING SUMMARY REPORT\n" + "="*80 + "\n\n")
        f.write("üìÖ TH·ªúI GIAN:\n")
        f.write(f"  ‚Ä¢ B·∫Øt ƒë·∫ßu: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"  ‚Ä¢ K·∫øt th√∫c: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"  ‚Ä¢ T·ªïng th·ªùi gian: {training_duration:.2f}s ({training_duration/60:.2f} ph√∫t)\n\n")
        f.write("‚öôÔ∏è  C·∫§U H√åNH:\n")
        f.write(f"  ‚Ä¢ Chi·∫øn l∆∞·ª£c: {config['algorithm'].upper()}\n")
        if config['algorithm'] == 'fedprox':
            f.write(f"  ‚Ä¢ Mu (proximal): {config['mu']}\n")
        f.write(f"  ‚Ä¢ S·ªë clients: {config['num_clients']}\n")
        f.write(f"  ‚Ä¢ S·ªë rounds: {config['num_rounds']}\n")
        f.write(f"  ‚Ä¢ Epochs/round: {config['local_epochs']}\n")
        f.write(f"  ‚Ä¢ Batch size: {config['batch_size']}\n")
        f.write(f"  ‚Ä¢ Learning rate: {config['learning_rate']}\n")
        f.write(f"  ‚Ä¢ Input features: {config['input_shape'][0]}\n")
        f.write(f"  ‚Ä¢ Num classes: {config['num_classes']}\n")
        f.write(f"  ‚Ä¢ Ch·∫°y song song: {config['use_multiprocessing']}\n")
        
        f.write("\nüìä K·∫æT QU·∫¢ CU·ªêI C√ôNG (T·ªîNG H·ª¢P T·ª™ TEST SET):\n")
        if history['test_accuracy']:
            final_acc = history['test_accuracy'][-1]
            final_loss = history['test_loss'][-1]
            f.write(f"  ‚Ä¢ Final Test Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\n")
            f.write(f"  ‚Ä¢ Final Test Loss: {final_loss:.4f}\n")
        
        f.write("\nüìÅ OUTPUT FILES:\n")
        f.write(f"  ‚Ä¢ Th∆∞ m·ª•c: {OUTPUT_DIR}\n")
        f.write(f"  ‚Ä¢ Model: global_model.pth\n")
        f.write(f"  ‚Ä¢ History: training_history.pkl\n")
        f.write(f"  ‚Ä¢ Plots: training_history.png\n")
        f.write(f"  ‚Ä¢ Report: classification_report.txt\n")
        f.write(f"  ‚Ä¢ Metrics: detailed_metrics.csv\n")
        f.write(f"  ‚Ä¢ Config: config.json\n")
        
        f.write("\n" + "="*80 + "\n" + "‚úÖ HU·∫§N LUY·ªÜN TH√ÄNH C√îNG!\n" + "="*80 + "\n")

    logger.info(f"‚úÖ ƒê√£ t·∫°o summary report: {summary_path}")

# ============================================================================
# üí° B∆Ø·ªöC 11: H√ÄM MAIN (ƒê·ªÇ CH·∫†Y) üí°
# ============================================================================

def main():
    config = CONFIG
    start_time = datetime.now()

    logger.info("="*80)
    logger.info("ü§ñ FEDERATED LEARNING V·ªöI M√î H√åNH CNN-GRU (IoT IDS)")
    logger.info("="*80)

    try:
        # B∆∞·ªõc 1: Ki·ªÉm tra thi·∫øt b·ªã
        device = check_and_setup_gpu(config)
        config['device'] = device

        # B∆∞·ªõc 2: T·ª± ƒë·ªông ph√°t hi·ªán tham s·ªë d·ªØ li·ªáu
        input_shape, num_classes, data_stats = auto_detect_data_parameters(
            data_dir=config['data_dir'],
            num_clients=config['num_clients']
        )
        config['input_shape'] = input_shape
        config['num_classes'] = num_classes

        # In c·∫•u h√¨nh cu·ªëi c√πng
        logger.info("\n" + "="*80)
        logger.info("‚öôÔ∏è  C·∫§U H√åNH CU·ªêI C√ôNG")
        logger.info("="*80)
        # Chuy·ªÉn config sang string ƒë·ªÉ in
        config_str = json.dumps(config, indent=2, default=str)
        print(config_str) # D√πng print ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp
        logger.info("="*80)

        # B∆∞·ªõc 3: Load d·ªØ li·ªáu
        train_loaders, test_loaders = load_federated_data(
            data_dir=config['data_dir'],
            num_clients=config['num_clients'],
            batch_size=config['batch_size'],
            device=config['device']
        )
        
        # N·∫øu d√πng multiprocessing, ch√∫ng ta c·∫ßn gi·ªØ ch·ªó (placeholder)
        # v√¨ kh√¥ng th·ªÉ truy·ªÅn DataLoader qua c√°c process
        client_train_loaders = train_loaders
        if config['use_multiprocessing']:
            client_train_loaders = [None] * config['num_clients'] # Ch·ªâ l√† gi·ªØ ch·ªó


        # B∆∞·ªõc 4: Kh·ªüi t·∫°o h·ªá th·ªëng federated
        server, clients = initialize_federated_system(
            config=config, # Truy·ªÅn config v√†o
            train_loaders=client_train_loaders, # S·∫Ω l√† [None, None,...] n·∫øu d√πng multiprocessing
            test_loaders=test_loaders
        )

        # B∆∞·ªõc 5: Hu·∫•n luy·ªán federated
        history = train_federated(
            server, 
            config, 
            train_loaders=train_loaders # Truy·ªÅn Dataloader th·∫≠t (ch·ªâ d√πng n·∫øu multiprocessing)
        )
        
        end_time = datetime.now()
        training_duration = (end_time - start_time).total_seconds()
        
        logger.info("\n" + "="*80)
        logger.info("üèÅ HU·∫§N LUY·ªÜN HO√ÄN T·∫§T!")
        logger.info("="*80)
        logger.info(f"‚è±Ô∏è  Th·ªùi gian hu·∫•n luy·ªán: {training_duration:.2f} gi√¢y ({training_duration/60:.2f} ph√∫t)")

        # B∆∞·ªõc 6: L∆∞u k·∫øt qu·∫£
        evaluate_and_save_results(
            server, history, config, 
            config['output_dir'], data_stats,
            training_duration, start_time, end_time
        )
        
        logger.info("\n" + "="*80)
        logger.info("üéâ üéâ üéâ  HO√ÄN T·∫§T T·∫§T C·∫¢ C√ÅC B∆Ø·ªöC  üéâ üéâ üéâ")
        logger.info("="*80)

    except Exception as e:
        logger.error("\n‚ùå ƒê√É X·∫¢Y RA L·ªñI TRONG QU√Å TR√åNH CH·∫†Y SCRIPT")
        logger.error(f"Chi ti·∫øt l·ªói: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    # Thi·∫øt l·∫≠p 'spawn' l√† ph∆∞∆°ng th·ª©c b·∫Øt ƒë·∫ßu cho multiprocessing
    # B·∫ÆT BU·ªòC ph·∫£i ƒë·∫∑t trong block if __name__ == "__main__":
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError as e:
        # B·ªè qua l·ªói n·∫øu n√≥ ƒë√£ ƒë∆∞·ª£c set
        if "context has already been set" not in str(e):
            logger.warning(f"Kh√¥ng th·ªÉ set 'spawn' start method: {e}")
        
    main()