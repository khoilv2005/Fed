################################################################################
#                                                                              #
#  SCRIPT HU·∫§N LUY·ªÜN FEDERATED LEARNING (FLOWER) HO√ÄN CH·ªàNH                   #
#  Framework: T·ª± build (PyTorch) - 1 FILE DUY NH·∫§T                             #
#  M√¥ h√¨nh: CNN-GRU ƒê·∫¶Y ƒê·ª¶ (Full Model)                                        #
#  Chi·∫øn l∆∞·ª£c: üåü FedAvg & FedProx (T·ª± code) üåü                                #
#  T√≠nh nƒÉng: ‚ö° T·ªêI ∆ØU GPU + SONG SONG (Multiprocessing) + B√ÅO C√ÅO F1-Score   #
#                                                                              #
################################################################################

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset
import torch.multiprocessing as mp  # Th√™m th∆∞ vi·ªán multiprocessing
import numpy as np
import matplotlib.pyplot as plt
import os
import logging
import pickle
import json
import copy
from collections import OrderedDict
from typing import List, Dict, Tuple
from datetime import datetime
from tqdm.auto import tqdm  # ‚úÖ Th√™m tqdm cho progress bar
import time  # ‚úÖ ƒê·ªÉ ƒëo th·ªùi gian m·ªói batch


# H√†m check gpu
def check_and_setup_gpu(config: Dict) -> str:
    """
    Ki·ªÉm tra xem GPU (CUDA) c√≥ kh·∫£ d·ª•ng hay kh√¥ng,
    v√† thi·∫øt l·∫≠p thi·∫øt b·ªã ('cuda' ho·∫∑c 'cpu') ƒë·ªÉ s·ª≠ d·ª•ng.
    """

    # Ki·ªÉm tra c·∫•u h√¨nh v√† kh·∫£ nƒÉng c·ªßa h·ªá th·ªëng
    if config.get('force_gpu', False) and not torch.cuda.is_available():
        device = 'cpu'
        logger.warning(
            "‚ö†Ô∏è L·ªñI C·∫§U H√åNH: B·∫°n y√™u c·∫ßu 'force_gpu=True' nh∆∞ng kh√¥ng t√¨m th·∫•y GPU (CUDA). "
            "Bu·ªôc ph·∫£i chuy·ªÉn sang ch·∫°y tr√™n CPU."
        )
    elif torch.cuda.is_available() and config['device'] == 'cuda':
        device = 'cuda'
        # Thi·∫øt l·∫≠p device ƒë·ªÉ in ra th√¥ng tin GPU
        current_device = torch.cuda.current_device()
        device_name = torch.cuda.get_device_name(current_device)
        logger.info(f"‚úÖ ƒê√£ ph√°t hi·ªán v√† s·ª≠ d·ª•ng GPU/CUDA: {device_name}")
    else:
        # N·∫øu c·∫•u h√¨nh l√† 'cpu' ho·∫∑c kh√¥ng c√≥ GPU
        device = 'cpu'
        logger.info("‚öôÔ∏è Ch·∫°y tr√™n CPU theo c·∫•u h√¨nh ho·∫∑c do kh√¥ng t√¨m th·∫•y GPU.")

    # C·∫≠p nh·∫≠t c·∫•u h√¨nh v√† tr·∫£ v·ªÅ thi·∫øt b·ªã
    config['device'] = device
    return device


# ============================================
# === TH√äM TH∆Ø VI·ªÜN CHO BI·ªÇU ƒê·ªí V√Ä K·∫æT QU·∫¢ ===
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    precision_recall_fscore_support
)
import pandas as pd
# ============================================

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# üí° B∆Ø·ªöC 1: C·∫§U H√åNH CH√çNH üí°
# ============================================================================

CONFIG = {
    # ‚¨áÔ∏è CH·ªàNH ƒê∆Ø·ªúNG D·∫™N N√ÄY (TR√äN COLAB C·∫¶N MOUNT DRIVE TR∆Ø·ªöC) ‚¨áÔ∏è
    'data_dir': '/content/drive/MyDrive/Fed-Data/5-Client',
    'output_dir': '/content/drive/MyDrive/Fed-Data/5-Client/Results',  # L∆∞u k·∫øt qu·∫£

    'num_clients': 5,

    # Model params (s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông ph√°t hi·ªán t·ª´ data)
    'input_shape': None,  # T·ª± ƒë·ªông ph√°t hi·ªán
    'num_classes': None,  # T·ª± ƒë·ªông ph√°t hi·ªán

    # Training params
    'algorithm': 'fedavg',     # 'fedavg' ho·∫∑c 'fedprox'
    'num_rounds': 10,           # Gi·∫£m s·ªë round cho ch·∫°y th·ª≠ nghi·ªám nhanh
    'local_epochs': 5,         # 1 Epoch/V√≤ng
    'learning_rate': 0.001,
    'batch_size': 1024,        # Batch size l·ªõn (GPU 15GB ok)
    'client_fraction': 1.0,    # T·ªâ l·ªá clients tham gia m·ªói round

    # FedProx specific
    'mu': 0.01,  # Proximal term coefficient

    # Device - Lu√¥n ∆∞u ti√™n GPU
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'force_gpu': True,  # Set False n·∫øu mu·ªën cho ph√©p ch·∫°y tr√™n CPU

    # Multiprocessing
    'use_multiprocessing': True,   # Ch·∫°y clients song song
    'num_processes': 2,            # QUAN TR·ªåNG: V·ªõi 2 GPUs, d√πng 2 processes (1 process/GPU)
                                   # - Tr√°nh nhi·ªÅu processes c√πng d√πng 1 GPU g√¢y OOM
                                   # - M·ªói process s·∫Ω train 1 client t·∫°i 1 th·ªùi ƒëi·ªÉm
                                   # - Pool s·∫Ω t·ª± ƒë·ªông l·∫•y client ti·∫øp theo khi worker r·∫£nh
                                   # L∆∞u √Ω:
                                   # - V·ªõi 1 GPU: num_processes = 1
                                   # - V·ªõi 2 GPUs: num_processes = 2 (khuy·∫øn ngh·ªã)
                                   # - V·ªõi 4+ GPUs: num_processes = num_gpus

    # Visualization
    'eval_every': 1,
}

# === T·∫†O TH∆Ø M·ª§C OUTPUT ===
TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
OUTPUT_DIR = os.path.join(CONFIG['output_dir'], f"run_{TIMESTAMP}_{CONFIG['algorithm']}")
os.makedirs(OUTPUT_DIR, exist_ok=True)
CONFIG['output_dir'] = OUTPUT_DIR  # C·∫≠p nh·∫≠t config v·ªõi ƒë∆∞·ªùng d·∫´n m·ªõi

# ============================================================================
# üí° B∆Ø·ªöC 2: ƒê·ªäNH NGHƒ®A M√î H√åNH CNN-GRU üí°
# ============================================================================


class CNN_GRU_Model(nn.Module):
    """
    M√¥ h√¨nh CNN-GRU (CNN + GRU + MLP + Softmax) b·∫±ng PyTorch
    (Phi√™n b·∫£n T·ªêI ∆ØU T·ªêC ƒê·ªò, ƒë√£ t·∫Øt recurrent_dropout)
    """
    def __init__(self, input_shape, num_classes=2):
        super(CNN_GRU_Model, self).__init__()

        if isinstance(input_shape, tuple):
            seq_length = input_shape[0]
        else:
            seq_length = input_shape

        self.input_shape = input_shape
        self.num_classes = num_classes

        # ===== CNN MODULE =====
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm1d(64)
        self.pool1 = nn.MaxPool1d(kernel_size=2)
        self.dropout_cnn1 = nn.Dropout(0.2)

        # Conv Block 2
        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm1d(128)
        self.pool2 = nn.MaxPool1d(kernel_size=2)
        self.dropout_cnn2 = nn.Dropout(0.2)

        # Conv Block 3
        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm1d(256)
        self.pool3 = nn.MaxPool1d(kernel_size=2)
        self.dropout_cnn3 = nn.Dropout(0.3)

        # T√≠nh to√°n k√≠ch th∆∞·ªõc output c·ªßa CNN
        def conv_output_shape(L_in, kernel_size=1, stride=1, padding=0, dilation=1):
            return (L_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride + 1

        cnn_output_length = seq_length
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=3, stride=1, padding=1)  # conv1
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=2, stride=2)            # pool1
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=3, stride=1, padding=1)  # conv2
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=2, stride=2)            # pool2
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=3, stride=1, padding=1)  # conv3
        cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=2, stride=2)            # pool3

        self.cnn_output_size = 256 * cnn_output_length

        # ===== GRU MODULE =====
        self.gru1 = nn.GRU(input_size=1, hidden_size=128, batch_first=True)
        self.gru2 = nn.GRU(input_size=128, hidden_size=64, batch_first=True)
        self.gru_output_size = 64

        # ===== MLP MODULE =====
        concat_size = self.cnn_output_size + self.gru_output_size

        self.dense1 = nn.Linear(concat_size, 256)
        self.bn_mlp1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(0.4)

        self.dense2 = nn.Linear(256, 128)
        self.bn_mlp2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(0.3)

        self.output = nn.Linear(128, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        if len(x.shape) == 2:
            x = x.unsqueeze(-1)

        batch_size = x.size(0)

        # ===== CNN =====
        x_cnn = x.permute(0, 2, 1)

        x_cnn = self.pool1(self.relu(self.bn1(self.conv1(x_cnn))))
        x_cnn = self.dropout_cnn1(x_cnn)

        x_cnn = self.pool2(self.relu(self.bn2(self.conv2(x_cnn))))
        x_cnn = self.dropout_cnn2(x_cnn)

        x_cnn = self.pool3(self.relu(self.bn3(self.conv3(x_cnn))))
        x_cnn = self.dropout_cnn3(x_cnn)

        cnn_output = x_cnn.view(batch_size, -1)

        # ===== GRU =====
        x_gru = x
        x_gru, _ = self.gru1(x_gru)
        x_gru, _ = self.gru2(x_gru)
        gru_output = x_gru[:, -1, :]

        # ===== CONCAT =====
        concatenated = torch.cat([cnn_output, gru_output], dim=1)

        # ===== MLP =====
        x = self.dense1(concatenated)
        if x.shape[0] > 1:  # BatchNorm y√™u c·∫ßu batch_size > 1
            x = self.bn_mlp1(x)
        x = self.relu(x)
        x = self.dropout1(x)

        x = self.dense2(x)
        if x.shape[0] > 1:
            x = self.bn_mlp2(x)
        x = self.relu(x)
        x = self.dropout2(x)

        out = self.output(x)
        return out


def build_cnn_gru_model(input_shape, num_classes=2):
    """H√†m ti·ªán √≠ch ƒë·ªÉ kh·ªüi t·∫°o model CNN-GRU."""
    model = CNN_GRU_Model(input_shape, num_classes)
    print(f"\n‚úÖ Kh·ªüi t·∫°o m√¥ h√¨nh CNN-GRU th√†nh c√¥ng")
    print(f"   - K√≠ch th∆∞·ªõc input: {input_shape}")
    print(f"   - S·ªë l·ªõp (num_classes): {num_classes}")
    return model


# ============================================================================
# üí° B∆Ø·ªöC 3: ƒê·ªäNH NGHƒ®A CLIENT FEDERATED üí°
# ============================================================================

class FederatedClient:
    """
    M·ªói client c√≥ d·ªØ li·ªáu ri√™ng v√† hu·∫•n luy·ªán m√¥ h√¨nh local.
    """
    def __init__(
        self,
        client_id: int,
        model: nn.Module,
        train_loader: DataLoader,
        test_loader: DataLoader = None,
        device: str = 'cpu'
    ):
        self.client_id = client_id
        self.model = model
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.device = device
        self.model.to(device)

    def get_model_params(self) -> OrderedDict:
        """L·∫•y tham s·ªë m√¥ h√¨nh c·ªßa client."""
        return copy.deepcopy(self.model.state_dict())

    def set_model_params(self, params: OrderedDict):
        """C·∫≠p nh·∫≠t tham s·ªë cho m√¥ h√¨nh client."""
        self.model.load_state_dict(params)

    def train_fedavg(
        self,
        epochs: int,
        learning_rate: float = 0.01,
        verbose: int = 1
    ) -> Dict:
        """
        Hu·∫•n luy·ªán local v·ªõi FedAvg.
        C√≥ progress bar chi ti·∫øt cho t·ª´ng batch.
        """
        self.model.train()
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()

        total_loss = 0.0
        total_samples = 0

        for epoch in range(epochs):
            epoch_loss = 0.0
            epoch_samples = 0

            if verbose:
                pbar = tqdm(
                    self.train_loader,
                    desc=f"[Client {self.client_id}] FedAvg Epoch {epoch+1}/{epochs}",
                    unit="batch",
                    leave=False
                )
            else:
                pbar = self.train_loader

            for batch_idx, (data, target) in enumerate(pbar):
                batch_start = time.time()

                data, target = data.to(self.device), target.to(self.device)

                optimizer.zero_grad()
                output = self.model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()

                batch_time = time.time() - batch_start

                epoch_loss += loss.item() * data.size(0)
                epoch_samples += data.size(0)

                if verbose:
                    pbar.set_postfix({
                        "loss": f"{loss.item():.4f}",
                        "lr": f"{optimizer.param_groups[0]['lr']:.1e}",
                        "bt": f"{batch_time*1000:.0f}ms"
                    })

            avg_loss = epoch_loss / max(1, epoch_samples)
            total_loss += epoch_loss
            total_samples += epoch_samples

            if verbose:
                print(f"\nClient {self.client_id} - Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}")

        avg_total_loss = total_loss / max(1, total_samples)

        return {
            'client_id': self.client_id,
            'num_samples': total_samples // max(1, epochs),
            'loss': avg_total_loss
        }

    def train_fedprox(
        self,
        epochs: int,
        global_params: OrderedDict,
        mu: float = 0.01,
        learning_rate: float = 0.01,
        verbose: int = 0
    ) -> Dict:
        """
        Train model v·ªõi FedProx:
        loss = CE + (mu/2) * ||w - w_global||^2
        C√≥ progress bar hi·ªÉn th·ªã CE loss + Prox term.
        """
        self.model.train()
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()

        total_loss = 0.0
        total_samples = 0

        for epoch in range(epochs):
            epoch_loss = 0.0
            epoch_samples = 0

            if verbose:
                pbar = tqdm(
                    self.train_loader,
                    desc=f"[Client {self.client_id}] FedProx Epoch {epoch+1}/{epochs}",
                    unit="batch",
                    leave=False
                )
            else:
                pbar = self.train_loader

            for batch_idx, (data, target) in enumerate(pbar):
                batch_start = time.time()

                data, target = data.to(self.device), target.to(self.device)

                optimizer.zero_grad()
                output = self.model(data)

                # Loss chu·∫©n (cross entropy)
                ce_loss = criterion(output, target)

                # Proximal Term
                proximal_term = 0.0
                for name, param in self.model.named_parameters():
                    if param.requires_grad:
                        global_param = global_params[name].to(self.device)
                        proximal_term += torch.sum((param - global_param) ** 2)

                proximal_term = (mu / 2) * proximal_term
                loss = ce_loss + proximal_term

                loss.backward()
                optimizer.step()

                batch_time = time.time() - batch_start

                epoch_loss += ce_loss.item() * data.size(0)  # ch·ªâ log CE
                epoch_samples += data.size(0)

                if verbose:
                    prox_val = float(proximal_term.detach().cpu().item())
                    pbar.set_postfix({
                        "ce": f"{ce_loss.item():.4f}",
                        "prox": f"{prox_val:.2e}",
                        "lr": f"{optimizer.param_groups[0]['lr']:.1e}",
                        "bt": f"{batch_time*1000:.0f}ms"
                    })

            avg_loss = epoch_loss / max(1, epoch_samples)
            total_loss += epoch_loss
            total_samples += epoch_samples

            if verbose:
                print(f"\nClient {self.client_id} - Epoch {epoch+1}/{epochs}, Avg CE Loss: {avg_loss:.4f}")

        avg_total_loss = total_loss / max(1, total_samples)

        return {
            'client_id': self.client_id,
            'num_samples': total_samples // max(1, epochs),
            'loss': avg_total_loss
        }

    def evaluate(self) -> Dict:
        """ƒê√°nh gi√° model tr√™n test set c·ªßa client."""
        if self.test_loader is None:
            return {'accuracy': 0.0, 'loss': 0.0, 'num_samples': 0}

        self.model.eval()
        criterion = nn.CrossEntropyLoss()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for data, target in self.test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                loss = criterion(output, target)

                total_loss += loss.item() * data.size(0)
                pred = output.argmax(dim=1)
                correct += pred.eq(target).sum().item()
                total += data.size(0)

        accuracy = correct / total if total > 0 else 0.0
        avg_loss = total_loss / total if total > 0 else 0.0

        return {
            'accuracy': accuracy,
            'loss': avg_loss,
            'num_samples': total
        }


# ============================================================================
# üí° B∆Ø·ªöC 4: ƒê·ªäNH NGHƒ®A SERVER FEDERATED üí°
# ============================================================================

class FederatedServer:
    """
    Server qu·∫£n l√Ω global model v√† th·ª±c hi·ªán aggregation.
    """
    def __init__(
        self,
        model: nn.Module,
        clients: List[FederatedClient],
        client_test_loaders: List[DataLoader],
        device: str = 'cpu'
    ):
        self.global_model = model
        self.clients = clients
        self.client_test_loaders = client_test_loaders
        self.device = device
        self.global_model.to(device)

        self.history = {
            'train_loss': [],
            'test_accuracy': [],
            'test_loss': []
        }

    def get_global_params(self) -> OrderedDict:
        return copy.deepcopy(self.global_model.state_dict())

    def set_global_params(self, params: OrderedDict):
        self.global_model.load_state_dict(params)

    def distribute_model(self, client_list: List[FederatedClient]):
        """G·ª≠i tham s·ªë m√¥ h√¨nh to√†n c·ª•c xu·ªëng c√°c client ƒë∆∞·ª£c ch·ªçn."""
        global_params = self.get_global_params()
        for client in client_list:
            client.set_model_params(global_params)

    def aggregate_fedavg(self, client_results: List[Dict]) -> OrderedDict:
        """
        FedAvg aggregation (Fix dtype & BatchNorm).
        """
        total_samples = sum(result['num_samples'] for result in client_results)

        aggregated_params = self.get_global_params()

        # ƒê·∫∑t t·∫•t c·∫£ c√°c tham s·ªë float v·ªÅ 0
        for key in aggregated_params.keys():
            if aggregated_params[key].dtype in [torch.float32, torch.float64, torch.float16]:
                aggregated_params[key] = torch.zeros_like(aggregated_params[key])

        # Weighted sum (ch·ªâ cho c√°c tham s·ªë float)
        for result in client_results:
            client_id = result['client_id']
            num_samples = result['num_samples']
            weight = num_samples / max(1, total_samples)

            client = self.clients[client_id]
            client_params = client.get_model_params()

            for key in aggregated_params.keys():
                param = client_params[key]
                if param.dtype in [torch.float32, torch.float64, torch.float16]:
                    weight_tensor = torch.tensor(weight, dtype=param.dtype, device=param.device)
                    if aggregated_params[key].device != param.device:
                        aggregated_params[key] = aggregated_params[key].to(param.device)

                    aggregated_params[key] += weight_tensor * param
                else:
                    # Gi·ªØ l·∫°i gi√° tr·ªã c·ªßa client ƒë·∫ßu ti√™n
                    if client_id == client_results[0]['client_id']:
                        aggregated_params[key] = param

        return aggregated_params

    def train_round_fedavg(
        self,
        num_epochs: int,
        learning_rate: float = 0.01,
        client_fraction: float = 1.0,
        verbose: int = 1
    ) -> Dict:
        """
        Th·ª±c hi·ªán 1 round hu·∫•n luy·ªán v·ªõi FedAvg. (Tu·∫ßn t·ª±)
        """
        num_selected = max(1, int(len(self.clients) * client_fraction))
        selected_clients = np.random.choice(self.clients, num_selected, replace=False)

        if verbose:
            print(f"‚Üí [Round] Ch·ªçn {len(selected_clients)} client ƒë·ªÉ hu·∫•n luy·ªán...")

        self.distribute_model(selected_clients)

        client_results = []
        for idx, client in enumerate(selected_clients):
            if verbose:
                num_batches = len(client.train_loader)
                print(f"\n‚Üí Training Client {client.client_id} ({idx+1}/{num_selected}) - "
                      f"{len(client.train_loader.dataset):,} samples, {num_batches} batches")

            result = client.train_fedavg(
                epochs=num_epochs,
                learning_rate=learning_rate,
                verbose=verbose
            )
            client_results.append(result)
            if verbose:
                print(f"   ‚úì Client {client.client_id} completed - Avg Loss: {result['loss']:.4f}")

        if verbose:
            print(f"\n‚Üí [Round] ƒêang t·ªïng h·ª£p (aggregating) {len(client_results)} m√¥ h√¨nh...")

        aggregated_params = self.aggregate_fedavg(client_results)
        self.set_global_params(aggregated_params)

        avg_loss = float(np.mean([r['loss'] for r in client_results])) if client_results else 0.0

        if verbose:
            print(f"‚Üí [Round] Ho√†n th√†nh, Loss trung b√¨nh (train): {avg_loss:.4f}")

        return {'train_loss': avg_loss, 'num_clients': len(selected_clients)}

    def train_round_fedprox(
        self,
        num_epochs: int,
        mu: float = 0.01,
        learning_rate: float = 0.01,
        client_fraction: float = 1.0,
        verbose: int = 0
    ) -> Dict:
        """
        Th·ª±c hi·ªán 1 round hu·∫•n luy·ªán v·ªõi FedProx. (Tu·∫ßn t·ª±)
        """
        num_selected = max(1, int(len(self.clients) * client_fraction))
        selected_clients = np.random.choice(self.clients, num_selected, replace=False)

        if verbose:
            print(f"‚Üí [Round] Ch·ªçn {len(selected_clients)} client ƒë·ªÉ hu·∫•n luy·ªán (FedProx)...")

        global_params = self.get_global_params()
        self.distribute_model(selected_clients)

        client_results = []
        for idx, client in enumerate(selected_clients):
            if verbose:
                num_batches = len(client.train_loader)
                print(f"\n‚Üí Training Client {client.client_id} ({idx+1}/{num_selected}) - "
                      f"{len(client.train_loader.dataset):,} samples, {num_batches} batches")

            result = client.train_fedprox(
                epochs=num_epochs,
                global_params=global_params,
                mu=mu,
                learning_rate=learning_rate,
                verbose=verbose
            )
            client_results.append(result)
            if verbose:
                print(f"   ‚úì Client {client.client_id} completed - Avg CE Loss: {result['loss']:.4f}")

        if verbose:
            print(f"\n‚Üí [Round] ƒêang t·ªïng h·ª£p (aggregating) {len(client_results)} m√¥ h√¨nh...")

        aggregated_params = self.aggregate_fedavg(client_results)
        self.set_global_params(aggregated_params)

        avg_loss = float(np.mean([r['loss'] for r in client_results])) if client_results else 0.0

        if verbose:
            print(f"‚Üí [Round] Ho√†n th√†nh, Loss CE trung b√¨nh (train): {avg_loss:.4f}")

        return {'train_loss': avg_loss, 'num_clients': len(selected_clients)}

    def evaluate_global(self) -> Dict:
        """
        ƒê√°nh gi√° global model tr√™n T·∫§T C·∫¢ test set c·ªßa client (l·∫∑p qua t·ª´ng client),
        c√≥ progress bar chi ti·∫øt.
        """
        if self.client_test_loaders is None:
            print("‚ö†Ô∏è  [Server Evaluate] Kh√¥ng t√¨m th·∫•y client_test_loaders.")
            return {'accuracy': 0.0, 'loss': 0.0}

        self.global_model.eval()
        criterion = nn.CrossEntropyLoss()

        total_loss = 0.0
        correct = 0
        total = 0

        for loader_idx, loader in enumerate(self.client_test_loaders):
            pbar = tqdm(
                loader,
                desc=f"[Eval] Client TestLoader {loader_idx}",
                unit="batch",
                leave=False
            )
            with torch.no_grad():
                for data, target in pbar:
                    data, target = data.to(self.device), target.to(self.device)
                    output = self.global_model(data)
                    loss = criterion(output, target)

                    total_loss += loss.item() * data.size(0)
                    pred = output.argmax(dim=1)
                    correct += pred.eq(target).sum().item()
                    total += data.size(0)

                    if total > 0:
                        current_acc = correct / total
                        current_loss = total_loss / total
                        pbar.set_postfix({
                            "acc": f"{current_acc*100:.2f}%",
                            "loss": f"{current_loss:.4f}"
                        })

        accuracy = correct / total if total > 0 else 0.0
        avg_loss = total_loss / total if total > 0 else 0.0

        return {
            'accuracy': accuracy,
            'loss': avg_loss
        }


# ============================================================================
# üí° B∆Ø·ªöC 5: H√ÄM T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN THAM S·ªê D·ªÆ LI·ªÜU üí°
# ============================================================================

def auto_detect_data_parameters(data_dir, num_clients):
    """
    T·ª± ƒë·ªông ph√°t hi·ªán input_shape v√† num_classes.
    """
    print("\n" + "="*80)
    print("üìÇ T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN THAM S·ªê D·ªÆ LI·ªÜU")
    print("="*80)
    print(f"‚Üí Th∆∞ m·ª•c d·ªØ li·ªáu: {data_dir}")
    print(f"‚Üí S·ªë l∆∞·ª£ng client (d·ª± ki·∫øn): {num_clients}")

    try:
        all_labels = []
        data_stats = {}

        # L·∫•y k√≠ch th∆∞·ªõc input t·ª´ client_0
        client_0_path = os.path.join(data_dir, "client_0_data.npz")
        if not os.path.exists(client_0_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {client_0_path}")

        with np.load(client_0_path) as data:
            x_train_sample = data['X_train']
            input_features = x_train_sample.shape[1]
            input_shape = (input_features,)
            print(f"\n‚úÖ Th√¥ng tin t·ª´ client 0:")
            print(f"   - S·ªë ƒë·∫∑c tr∆∞ng (INPUT_FEATURES): {input_features}")
            print(f"   - input_shape: {input_shape}")

        print(f"\n‚Üí ƒêang qu√©t d·ªØ li·ªáu c·ªßa {num_clients} client ƒë·ªÉ th·ªëng k√™ nh√£n...")
        total_train = 0
        total_test = 0

        for i in range(num_clients):
            file_path = os.path.join(data_dir, f"client_{i}_data.npz")
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file: {file_path}")

            with np.load(file_path) as data:
                x_train = data['X_train']; y_train = data['y_train']
                x_test = data['X_test']; y_test = data['y_test']

                all_labels.append(y_train)
                unique_labels, counts = np.unique(y_train, return_counts=True)
                total_train += len(x_train)
                total_test += len(x_test)

                data_stats[i] = {
                    'train_samples': int(len(x_train)),
                    'test_samples': int(len(x_test)),
                    'unique_labels': int(len(unique_labels)),
                    'label_distribution': {str(k): int(v) for k, v in zip(unique_labels, counts)}
                }
                print(f"   - Client {i}: {len(x_train)} m·∫´u train, {len(x_test)} m·∫´u test, {len(unique_labels)} nh√£n")

        combined_labels = np.concatenate(all_labels)
        num_classes = len(np.unique(combined_labels))

        print("\nüìä T·ªïng h·ª£p to√†n b·ªô d·ªØ li·ªáu:")
        print(f"   - S·ªë l·ªõp (num_classes): {num_classes}")
        print(f"   - T·ªïng s·ªë m·∫´u train: {total_train:,}")
        print(f"   - T·ªïng s·ªë m·∫´u test:  {total_test:,}")
        print("="*80)

        return input_shape, num_classes, data_stats

    except FileNotFoundError as e:
        print("\n" + "="*80 +
              f"\n‚ùå L·ªñI: KH√îNG T√åM TH·∫§Y T·ªÜP D·ªÆ LI·ªÜU\nƒê∆∞·ªùng d·∫´n: {e.filename}\n" + "="*80)
        raise
    except KeyError as e:
        print("\n" + "="*80 +
              f"\n‚ùå L·ªñI: THI·∫æU KEY TRONG FILE .NPZ\nKey: {e}\n" + "="*80)
        raise


# ============================================================================
# üí° B∆Ø·ªöC 6: H√ÄM LOAD D·ªÆ LI·ªÜU üí°
# ============================================================================

class NumpyDataset(TensorDataset):
    """Dataset ti·ªán d·ª•ng ƒë·ªÉ wrap numpy array th√†nh TensorDataset."""
    def __init__(self, X, y, device='cpu'):
        if len(X.shape) == 3:
            X = X.squeeze(-1)  # (N, F, 1) -> (N, F)

        X = X.astype(np.float32)
        X_tensor = torch.from_numpy(X)
        y_tensor = torch.from_numpy(y).long()
        super().__init__(X_tensor, y_tensor)


def load_federated_data(data_dir, num_clients, batch_size, device='cpu'):
    """
    Load d·ªØ li·ªáu federated cho t·∫•t c·∫£ client.
    """
    print("\n" + "="*80)
    print("üì• LOADING FEDERATED DATA")
    print("="*80)
    print(f"‚Üí Thi·∫øt b·ªã hi·ªán d√πng: {device}")
    print(f"‚Üí S·ªë l∆∞·ª£ng client: {num_clients}\n")

    train_loaders = []
    test_loaders = []

    for client_id in range(num_clients):
        data_path = os.path.join(data_dir, f'client_{client_id}_data.npz')
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu c·ªßa client {client_id} t·∫°i: {data_path}")

        data = np.load(data_path)
        X_train = data['X_train']; y_train = data['y_train']
        X_test = data['X_test']; y_test = data['y_test']

        print(f"   - Client {client_id}: X_train {X_train.shape}, X_test {X_test.shape}")

        train_dataset = NumpyDataset(X_train, y_train, device)
        test_dataset = NumpyDataset(X_test, y_test, device)

        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True, drop_last=False
        )
        test_loader = DataLoader(
            test_dataset, batch_size=batch_size, shuffle=False, drop_last=False
        )
        train_loaders.append(train_loader)
        test_loaders.append(test_loader)

    print(f"\n‚úÖ ƒê√£ load d·ªØ li·ªáu cho {num_clients} client.")
    print("="*80)

    return train_loaders, test_loaders


# ============================================================================
# üí° B∆Ø·ªöC 7: H√ÄM KH·ªûI T·∫†O H·ªÜ TH·ªêNG üí°
# ============================================================================

def initialize_federated_system(
    train_loaders,
    test_loaders,
    input_shape,
    num_classes,
    device='cpu'
):
    """
    Kh·ªüi t·∫°o global model, clients, v√† server
    """
    print("\n" + "="*80)
    print("üèóÔ∏è  INITIALIZING FEDERATED SYSTEM")
    print("="*80)

    num_clients = len(train_loaders)

    # T·∫°o global model
    print(f"\n‚Üí Kh·ªüi t·∫°o m√¥ h√¨nh to√†n c·ª•c (global model)...")
    print(f"   - Input shape: {input_shape}")
    print(f"   - S·ªë l·ªõp: {num_classes}")
    print(f"   - Thi·∫øt b·ªã: {device}")

    global_model = build_cnn_gru_model(input_shape, num_classes)
    global_model = global_model.to(device)
    print(f"   - M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang thi·∫øt b·ªã: {device}")

    if isinstance(device, torch.device):
        device_type = device.type
    else:
        device_type = str(device)

    if device_type == 'cuda':
        print(f"   - X√°c nh·∫≠n tham s·ªë ƒë·∫ßu ti√™n c·ªßa m√¥ h√¨nh ƒëang ·ªü: {next(global_model.parameters()).device}")

    total_params = sum(p.numel() for p in global_model.parameters())
    trainable_params = sum(p.numel() for p in global_model.parameters() if p.requires_grad)
    print(f"   - T·ªïng s·ªë tham s·ªë: {total_params:,}")
    print(f"   - S·ªë tham s·ªë trainable: {trainable_params:,}")

    # T·∫°o clients
    print(f"\n‚Üí Kh·ªüi t·∫°o {num_clients} client...")
    clients = []

    for client_id in range(num_clients):
        client_model = CNN_GRU_Model(input_shape, num_classes)
        client_model.load_state_dict(global_model.state_dict())

        client = FederatedClient(
            client_id=client_id,
            model=client_model,
            train_loader=train_loaders[client_id],
            test_loader=test_loaders[client_id],
            device=device
        )
        clients.append(client)
        print(f"   - Client {client_id}: kh·ªüi t·∫°o th√†nh c√¥ng tr√™n thi·∫øt b·ªã {device}")

    print("\n‚Üí G√°n danh s√°ch test loader cho server (tr√°nh l·ªói RAM)...")

    # T·∫°o server
    print("\n‚Üí Kh·ªüi t·∫°o server...")
    server = FederatedServer(
        model=global_model,
        clients=clients,
        client_test_loaders=test_loaders,
        device=device
    )

    print("\n‚úÖ H·ªá th·ªëng Federated ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ho√†n ch·ªânh.")
    print("="*80)

    return server, clients


# ============================================================================
# üí° B∆Ø·ªöC 8: C√ÅC H√ÄM H·ªñ TR·ª¢ MULTIPROCESSING üí°
# ============================================================================
#
# üöÄ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG MULTIPROCESSING:
#
# 1. B·∫¨T MULTIPROCESSING:
#    - ƒê·∫∑t 'use_multiprocessing': True trong CONFIG
#    - ƒê·∫∑t 'num_processes': N (N = s·ªë processes mu·ªën ch·∫°y song song)
#
# 2. CH·ªåN S·ªê PROCESSES PH√ô H·ª¢P:
#    - V·ªõi CPU: num_processes = s·ªë CPU cores (v√≠ d·ª•: 4-8)
#    - V·ªõi 1 GPU: num_processes = 2-3 (tr√°nh OOM)
#    - V·ªõi nhi·ªÅu GPUs: num_processes = num_gpus * 2 ho·∫∑c = num_clients
#    - L∆∞u √Ω: M·ªói process c·∫ßn RAM ri√™ng, c·∫ßn ƒë·ªß RAM cho t·∫•t c·∫£ processes
#
# 3. L·ª¢I √çCH:
#    - TƒÉng t·ªëc ƒë√°ng k·ªÉ khi train nhi·ªÅu clients (c√≥ th·ªÉ nhanh g·∫•p 2-5 l·∫ßn)
#    - T·∫≠n d·ª•ng ƒë∆∞·ª£c nhi·ªÅu GPU n·∫øu c√≥
#    - M·ªói client train ho√†n to√†n ƒë·ªôc l·∫≠p, kh√¥ng ·∫£nh h∆∞·ªüng l·∫´n nhau
#
# 4. L∆ØU √ù:
#    - C·∫ßn ƒë·ªß RAM/VRAM cho t·∫•t c·∫£ processes
#    - N·∫øu g·∫∑p OOM (Out Of Memory), gi·∫£m num_processes ho·∫∑c batch_size
#    - V·ªõi 1 GPU, kh√¥ng n√™n d√πng qu√° 3 processes
#
# ============================================================================

def _client_training_worker(args_tuple):
    """
    H√†m worker (helper) ƒë·ªÉ ch·∫°y trong m·ªôt process ri√™ng bi·ªát.
    C√≥ tqdm ri√™ng cho t·ª´ng worker.

    QUAN TR·ªåNG: H√†m n√†y ch·∫°y trong process ri√™ng v·ªõi spawn context,
    n√™n c·∫ßn import l·∫°i t·∫•t c·∫£ dependencies v√† tr√°nh chia s·∫ª CUDA tensors.
    """
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import numpy as np
    from collections import OrderedDict
    from tqdm.auto import tqdm as _tqdm
    import time as _time
    import os

    # T·∫Øt c·∫£nh b√°o CUDA kh√¥ng c·∫ßn thi·∫øt trong worker processes
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'

    class CNN_GRU_Model_Worker(nn.Module):
        def __init__(self, input_shape, num_classes=2):
            super(CNN_GRU_Model_Worker, self).__init__()
            if isinstance(input_shape, tuple):
                seq_length = input_shape[0]
            else:
                seq_length = input_shape
            self.input_shape = input_shape
            self.num_classes = num_classes
            self.conv1 = nn.Conv1d(1, 64, 3, padding=1)
            self.bn1 = nn.BatchNorm1d(64)
            self.pool1 = nn.MaxPool1d(2)
            self.dropout_cnn1 = nn.Dropout(0.2)
            self.conv2 = nn.Conv1d(64, 128, 3, padding=1)
            self.bn2 = nn.BatchNorm1d(128)
            self.pool2 = nn.MaxPool1d(2)
            self.dropout_cnn2 = nn.Dropout(0.2)
            self.conv3 = nn.Conv1d(128, 256, 3, padding=1)
            self.bn3 = nn.BatchNorm1d(256)
            self.pool3 = nn.MaxPool1d(2)
            self.dropout_cnn3 = nn.Dropout(0.3)

            def conv_output_shape(L_in, kernel_size=1, stride=1, padding=0, dilation=1):
                return (L_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride + 1

            cnn_output_length = seq_length
            for _ in range(3):
                cnn_output_length = conv_output_shape(cnn_output_length, kernel_size=2, stride=2)
            self.cnn_output_size = 256 * cnn_output_length
            self.gru1 = nn.GRU(1, 128, batch_first=True)
            self.gru2 = nn.GRU(128, 64, batch_first=True)
            self.gru_output_size = 64
            concat_size = self.cnn_output_size + self.gru_output_size
            self.dense1 = nn.Linear(concat_size, 256)
            self.bn_mlp1 = nn.BatchNorm1d(256)
            self.dropout1 = nn.Dropout(0.4)
            self.dense2 = nn.Linear(256, 128)
            self.bn_mlp2 = nn.BatchNorm1d(128)
            self.dropout2 = nn.Dropout(0.3)
            self.output = nn.Linear(128, num_classes)
            self.relu = nn.ReLU()

        def forward(self, x):
            if len(x.shape) == 2:
                x = x.unsqueeze(-1)
            batch_size = x.size(0)
            x_cnn = x.permute(0, 2, 1)
            x_cnn = self.dropout_cnn1(self.pool1(self.relu(self.bn1(self.conv1(x_cnn)))))
            x_cnn = self.dropout_cnn2(self.pool2(self.relu(self.bn2(self.conv2(x_cnn)))))
            x_cnn = self.dropout_cnn3(self.pool3(self.relu(self.bn3(self.conv3(x_cnn)))))
            cnn_output = x_cnn.view(batch_size, -1)
            x_gru = x
            x_gru, _ = self.gru1(x_gru)
            x_gru, _ = self.gru2(x_gru)
            gru_output = x_gru[:, -1, :]
            concatenated = torch.cat([cnn_output, gru_output], dim=1)
            x = self.dense1(concatenated)
            if x.shape[0] > 1:
                x = self.bn_mlp1(x)
            x = self.relu(x)
            x = self.dropout1(x)
            x = self.dense2(x)
            if x.shape[0] > 1:
                x = self.bn_mlp2(x)
            x = self.relu(x)
            x = self.dropout2(x)
            return self.output(x)

    class NumpyDataset_Worker(TensorDataset):
        def __init__(self, X, y):
            if len(X.shape) == 3:
                X = X.squeeze(-1)
            X = X.astype(np.float32)
            X_tensor = torch.from_numpy(X)
            y_tensor = torch.from_numpy(y).long()
            super().__init__(X_tensor, y_tensor)

    try:
        (client_id, model_state_dict, train_data, device_id, config) = args_tuple

        # Debug: In ra ƒë·ªÉ bi·∫øt worker ƒë√£ start
        print(f"   üöÄ Worker cho Client {client_id} ƒë√£ start (device: {device_id})")

        num_epochs = config['local_epochs']
        learning_rate = config['learning_rate']
        algorithm = config['algorithm']
        mu = config['mu']
        batch_size = config['batch_size']

        # Thi·∫øt l·∫≠p device cho worker process
        if device_id != 'cpu' and torch.cuda.is_available():
            # ƒê·∫£m b·∫£o device_id h·ª£p l·ªá
            num_gpus = torch.cuda.device_count()
            if isinstance(device_id, int) and device_id < num_gpus:
                device = torch.device(f'cuda:{device_id}')
                torch.cuda.set_device(device)  # Set device m·∫∑c ƒë·ªãnh cho process n√†y
            else:
                device = torch.device('cuda:0')  # Fallback to first GPU
                torch.cuda.set_device(0)
        else:
            device = torch.device('cpu')

        X_train, y_train = train_data

        train_dataset = NumpyDataset_Worker(X_train, y_train)
        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True, drop_last=False
        )

        model = CNN_GRU_Model_Worker(config['input_shape'], config['num_classes'])
        model.load_state_dict(model_state_dict)
        model = model.to(device)

        model.train()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()

        total_loss = 0.0
        total_samples = 0

        for epoch in range(num_epochs):
            epoch_loss = 0.0
            epoch_samples = 0

            pbar = _tqdm(
                train_loader,
                desc=f"[Worker Client {client_id}] Epoch {epoch+1}/{num_epochs}",
                unit="batch",
                leave=False
            )

            for data, target in pbar:
                batch_start = _time.time()

                data, target = data.to(device), target.to(device)

                optimizer.zero_grad()
                output = model(data)
                ce_loss = criterion(output, target)

                if algorithm == 'fedprox' and model_state_dict is not None:
                    proximal_term = 0.0
                    for name, param in model.named_parameters():
                        if param.requires_grad:
                            global_param = model_state_dict[name].to(device)
                            proximal_term += torch.sum((param - global_param) ** 2)
                    loss = ce_loss + (mu / 2) * proximal_term
                    prox_val = float(((mu / 2) * proximal_term).detach().cpu().item())
                else:
                    loss = ce_loss
                    prox_val = 0.0

                loss.backward()
                optimizer.step()

                batch_time = _time.time() - batch_start

                epoch_loss += ce_loss.item() * data.size(0)
                epoch_samples += data.size(0)

                pbar.set_postfix({
                    "ce": f"{ce_loss.item():.4f}",
                    "prox": f"{prox_val:.2e}",
                    "lr": f"{optimizer.param_groups[0]['lr']:.1e}",
                    "bt": f"{batch_time*1000:.0f}ms"
                })

            total_loss += epoch_loss
            total_samples += epoch_samples

            # D·ªçn d·∫πp CUDA cache sau m·ªói epoch ƒë·ªÉ tr√°nh OOM
            if device.type == 'cuda':
                torch.cuda.empty_cache()

        avg_loss = total_loss / max(1, total_samples)

        # D·ªçn d·∫πp cu·ªëi c√πng tr∆∞·ªõc khi return
        if device.type == 'cuda':
            torch.cuda.empty_cache()

        return {
            'client_id': client_id,
            'model_state_dict': {k: v.cpu() for k, v in model.state_dict().items()},
            'num_samples': len(X_train),
            'loss': avg_loss
        }

    except Exception as e:
        print(f"\n{'='*60}")
        print(f"‚ùå L·ªñI TRONG WORKER CLIENT {client_id}")
        print(f"{'='*60}")
        print(f"Device: {device_id}")
        print(f"Error type: {type(e).__name__}")
        print(f"Error message: {e}")
        print(f"{'='*60}")
        import traceback
        traceback.print_exc()
        print(f"{'='*60}\n")
        return None


def aggregate_models_fedavg_parallel(client_results: List[Dict]) -> OrderedDict:
    """
    FedAvg aggregation t·ª´ client results (Ch·∫°y tr√™n CPU)
    """
    total_samples = sum(r['num_samples'] for r in client_results)

    aggregated_params = OrderedDict()
    first_state = client_results[0]['model_state_dict']

    for key in first_state.keys():
        aggregated_params[key] = torch.zeros_like(first_state[key])

    for result in client_results:
        weight = result['num_samples'] / max(1, total_samples)
        state_dict = result['model_state_dict']

        for key in aggregated_params.keys():
            param = state_dict[key]

            if param.dtype in [torch.float32, torch.float64, torch.float16]:
                weight_tensor = torch.tensor(weight, dtype=param.dtype, device=param.device)
                aggregated_params[key] += weight_tensor * param
            else:
                if result['client_id'] == client_results[0]['client_id']:
                    aggregated_params[key] = param

    return aggregated_params


def train_round_multiprocessing(
    server,
    config,
    train_loaders,
    device='cuda'
):
    """
    Train 1 round v·ªõi multiprocessing - ch·∫°y nhi·ªÅu client song song.
    C√≥ tqdm cho danh s√°ch clients.
    """
    global_state_dict = {k: v.cpu() for k, v in server.get_global_params().items()}

    client_data = []
    for client_id, train_loader in enumerate(train_loaders):
        X_list, y_list = [], []
        for X_batch, y_batch in train_loader:
            X_list.append(X_batch.cpu().numpy())
            y_list.append(y_batch.cpu().numpy())
        X_train = np.concatenate(X_list, axis=0)
        y_train = np.concatenate(y_list, axis=0)
        client_data.append((X_train, y_train))

    # C·∫•u h√¨nh GPU allocation cho t·ª´ng client
    if device == 'cuda' and torch.cuda.is_available():
        num_gpus = torch.cuda.device_count()
        if num_gpus > 1:
            # Ph√¢n b·ªï clients ƒë·ªÅu tr√™n c√°c GPUs (round-robin)
            device_ids = [i % num_gpus for i in range(config['num_clients'])]
            print(f"   ‚Ä¢ Ph√¢n b·ªï {config['num_clients']} clients cho {num_gpus} GPUs (round-robin).")
            print(f"   ‚Ä¢ GPU mapping: {device_ids}")
        else:
            # Ch·ªâ c√≥ 1 GPU, t·∫•t c·∫£ clients d√πng chung (multiprocessing v·∫´n hi·ªáu qu·∫£)
            device_ids = [0] * config['num_clients']
            print(f"   ‚Ä¢ S·ª≠ d·ª•ng 1 GPU cho t·∫•t c·∫£ {config['num_clients']} clients.")
            print(f"   ‚Ä¢ ‚ö†Ô∏è  L∆∞u √Ω: C√°c processes s·∫Ω chia s·∫ª GPU, c·∫ßn ƒë·ªß VRAM!")
    else:
        device_ids = ['cpu'] * config['num_clients']
        print(f"   ‚Ä¢ S·ª≠ d·ª•ng CPU cho t·∫•t c·∫£ {config['num_clients']} clients.")

    args_list = [
        (
            client_id,
            global_state_dict,
            client_data[client_id],
            device_ids[client_id],
            config
        )
        for client_id in range(config['num_clients'])
    ]

    print(f"   ‚Ä¢ B·∫Øt ƒë·∫ßu train {config['num_clients']} clients song song v·ªõi {config['num_processes']} processes...")
    print(f"   ‚Ä¢ ƒêang kh·ªüi t·∫°o process pool...")

    # QUAN TR·ªåNG: D√πng spawn context cho CUDA
    # - Spawn: T·∫°o process m·ªõi ho√†n to√†n, tr√°nh CUDA fork issues
    # - Fork: Nhanh h∆°n NH∆ØNG kh√¥ng t∆∞∆°ng th√≠ch CUDA (g√¢y RuntimeError)
    mp_context = mp.get_context('spawn')
    results = []

    try:
        # T·∫°o pool v·ªõi s·ªë processes ƒë∆∞·ª£c c·∫•u h√¨nh (spawn method)
        print(f"   ‚Ä¢ T·∫°o pool v·ªõi {config['num_processes']} processes (spawn method)...")
        pool = mp_context.Pool(processes=config['num_processes'])

        print(f"   ‚Ä¢ Pool ƒë√£ ƒë∆∞·ª£c t·∫°o, b·∫Øt ƒë·∫ßu submit {len(args_list)} tasks...")

        # S·ª≠ d·ª•ng imap_unordered ƒë·ªÉ c√≥ th·ªÉ x·ª≠ l√Ω results ngay khi s·∫µn s√†ng
        for idx, res in enumerate(tqdm(
            pool.imap_unordered(_client_training_worker, args_list),
            total=len(args_list),
            desc="üîÑ Clients Training (Parallel)",
            unit="client"
        )):
            if res is not None:
                results.append(res)
                print(f"   ‚úì Client {res['client_id']} ho√†n th√†nh - Loss: {res['loss']:.4f}")
            else:
                print(f"   ‚úó M·ªôt client th·∫•t b·∫°i (tr·∫£ v·ªÅ None)")

        # ƒê·∫£m b·∫£o pool k·∫øt th√∫c ƒë√∫ng c√°ch
        print(f"   ‚Ä¢ ƒêang ƒë√≥ng pool...")
        pool.close()
        pool.join()
        print(f"   ‚Ä¢ Pool ƒë√£ ƒë∆∞·ª£c ƒë√≥ng th√†nh c√¥ng")

    except Exception as e:
        print(f"   ‚ùå L·ªói trong qu√° tr√¨nh multiprocessing: {e}")
        import traceback
        traceback.print_exc()
        # C·ªë g·∫Øng terminate pool n·∫øu c√≥ l·ªói
        try:
            pool.terminate()
            pool.join()
        except:
            pass
        raise

    # Ki·ªÉm tra k·∫øt qu·∫£
    results = [r for r in results if r is not None]

    if len(results) == 0:
        raise RuntimeError("T·∫•t c·∫£ clients ƒë·ªÅu th·∫•t b·∫°i!")

    print(f"   ‚Ä¢ ƒêang aggregate models t·ª´ {len(results)} clients...")
    aggregated_params_cpu = aggregate_models_fedavg_parallel(results)

    aggregated_params_gpu = OrderedDict(
        (k, v.to(device)) for k, v in aggregated_params_cpu.items()
    )
    server.set_global_params(aggregated_params_gpu)

    avg_loss = np.mean([r['loss'] for r in results])

    return {
        'train_loss': avg_loss,
        'num_clients': len(results)
    }


# ============================================================================
# üí° B∆Ø·ªöC 9: H√ÄM HU·∫§N LUY·ªÜN CH√çNH üí°
# ============================================================================

def train_federated(server, config, train_loaders=None):
    """
    ƒêi·ªÅu ph·ªëi qu√° tr√¨nh hu·∫•n luy·ªán (ch·ªçn tu·∫ßn t·ª± ho·∫∑c song song)
    C√≥ tqdm cho v√≤ng l·∫∑p rounds.
    """
    print("\n" + "="*80)
    print("üöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN FEDERATED")
    print("="*80)

    algorithm = config['algorithm']
    num_rounds = config['num_rounds']
    local_epochs = config['local_epochs']
    learning_rate = config['learning_rate']
    client_fraction = config['client_fraction']
    eval_every = config['eval_every']
    device = config['device']
    use_multiprocessing = config.get('use_multiprocessing', False)

    history = server.history

    print(f"\nüìã C·∫•u h√¨nh hu·∫•n luy·ªán:")
    print(f"   - Thu·∫≠t to√°n: {algorithm.upper()}")
    print(f"   - S·ªë round: {num_rounds}")
    print(f"   - S·ªë epoch local: {local_epochs}")
    print(f"   - Learning rate: {learning_rate}")
    print(f"   - Batch size: {config['batch_size']}")
    print(f"   - T·ªâ l·ªá client m·ªói round: {client_fraction}")
    print(f"   - Thi·∫øt b·ªã: {device}")
    print(f"   - Ch·∫°y song song (Multiprocessing): {use_multiprocessing}")
    if use_multiprocessing:
        print(f"   - S·ªë Processes: {config['num_processes']}")
        print(f"\n   ‚ö° MULTIPROCESSING ƒê√É ƒê∆Ø·ª¢C B·∫¨T!")
        print(f"   ‚Ä¢ {config['num_clients']} clients s·∫Ω ch·∫°y song song v·ªõi {config['num_processes']} processes")
        if device == 'cuda':
            num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0
            print(f"   ‚Ä¢ S·ªë GPU kh·∫£ d·ª•ng: {num_gpus}")
            if num_gpus > 0:
                print(f"   ‚Ä¢ Clients s·∫Ω ƒë∆∞·ª£c ph√¢n b·ªï t·ª± ƒë·ªông l√™n c√°c GPUs")
                if config['num_processes'] > num_gpus * 2:
                    print(f"   ‚ö†Ô∏è  C·∫¢NH B√ÅO: {config['num_processes']} processes cho {num_gpus} GPU(s) c√≥ th·ªÉ g√¢y OOM!")
                    print(f"   üí° Khuy·∫øn ngh·ªã: Gi·∫£m num_processes xu·ªëng {num_gpus * 2} ho·∫∑c √≠t h∆°n")
        print(f"   ‚Ä¢ M·ªói process s·∫Ω train ƒë·ªôc l·∫≠p, sau ƒë√≥ aggregate k·∫øt qu·∫£")
    if algorithm == 'fedprox':
        print(f"   - Mu (proximal term): {config['mu']}")

    if eval_every > 0:
        print("\nüìä ƒê√°nh gi√° m√¥ h√¨nh to√†n c·ª•c (ch∆∞a hu·∫•n luy·ªán)...")
        eval_result = server.evaluate_global()
        history['train_loss'].append(None)
        history['test_accuracy'].append(eval_result['accuracy'])
        history['test_loss'].append(eval_result['loss'])
        print(f"‚úÖ Round 0 (Init): Test Acc: {eval_result['accuracy']*100:.2f}% | Test Loss: {eval_result['loss']:.4f}")

    round_iter = tqdm(
        range(num_rounds),
        desc="Global Rounds",
        unit="round"
    )

    for round_idx in round_iter:
        print(f"\n{'='*60}")
        print(f"üìç ROUND {round_idx+1}/{num_rounds}")
        print(f"{'='*60}")

        if use_multiprocessing:
            if train_loaders is None:
                raise ValueError("train_loaders l√† b·∫Øt bu·ªôc khi d√πng multiprocessing")

            worker_config = config.copy()
            worker_config['local_epochs'] = local_epochs
            worker_config['learning_rate'] = learning_rate
            worker_config['algorithm'] = algorithm
            worker_config['mu'] = config.get('mu', 0.01)

            round_result = train_round_multiprocessing(
                server=server,
                config=worker_config,
                train_loaders=train_loaders,
                device=device
            )

        else:
            print("üìù Ch·∫ø ƒë·ªô: SEQUENTIAL - Clients ch·∫°y l·∫ßn l∆∞·ª£t (ch·∫≠m)...")
            if algorithm == 'fedavg':
                round_result = server.train_round_fedavg(
                    num_epochs=local_epochs,
                    learning_rate=learning_rate,
                    client_fraction=client_fraction,
                    verbose=1
                )
            elif algorithm == 'fedprox':
                round_result = server.train_round_fedprox(
                    num_epochs=local_epochs,
                    mu=config['mu'],
                    learning_rate=learning_rate,
                    client_fraction=client_fraction,
                    verbose=1
                )
            else:
                raise ValueError(f"Thu·∫≠t to√°n kh√¥ng h·ªó tr·ª£: {algorithm}")

        if (round_idx + 1) % eval_every == 0:
            print(f"\nüìä ƒêang ƒë√°nh gi√° m√¥ h√¨nh to√†n c·ª•c tr√™n test set...")
            eval_result = server.evaluate_global()

            history['train_loss'].append(round_result['train_loss'])
            history['test_accuracy'].append(eval_result['accuracy'])
            history['test_loss'].append(eval_result['loss'])

            print(f"\n‚úÖ Round {round_idx+1}/{num_rounds} Summary:")
            print(f"   ‚Ä¢ Train Loss (Avg): {round_result['train_loss']:.4f}")
            print(f"   ‚Ä¢ Test Accuracy: {eval_result['accuracy']*100:.2f}%")
            print(f"   ‚Ä¢ Test Loss: {eval_result['loss']:.4f}")

            round_iter.set_postfix({
                "algo": algorithm,
                "train_loss": f"{round_result['train_loss']:.4f}",
                "test_acc": f"{eval_result['accuracy']*100:.2f}%"
            })

    if history['test_accuracy']:
        print(f"\n‚úÖ Hu·∫•n luy·ªán {algorithm.upper()} ho√†n t·∫•t.")
        print(f"   ‚Üí ƒê·ªô ch√≠nh x√°c cu·ªëi c√πng tr√™n test: {history['test_accuracy'][-1]*100:.2f}%")
    else:
        print("\n‚ö†Ô∏è Kh√¥ng c√≥ k·∫øt qu·∫£ test n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")

    return history


# ============================================================================
# üí° B∆Ø·ªöC 10: H√ÄM V·∫º BI·ªÇU ƒê·ªí & L∆ØU K·∫æT QU·∫¢ üí°
# ============================================================================

def plot_training_history(history, save_path):
    """
    V·∫Ω bi·ªÉu ƒë·ªì train_loss, test_loss v√† test_accuracy theo round.
    """
    print("\n" + "="*80)
    print("üìä ƒêANG V·∫º BI·ªÇU ƒê·ªí K·∫æT QU·∫¢ HU·∫§N LUY·ªÜN")
    print("="*80)

    try:
        fig, axes = plt.subplots(1, 2, figsize=(16, 6))

        rounds = range(len(history['test_loss']))
        train_loss = history['train_loss']
        test_loss = history['test_loss']
        test_acc = history['test_accuracy']

        ax1 = axes[0]
        ax1.plot(rounds[1:], train_loss[1:], label='Train Loss (Trung b√¨nh Client)',
                 marker='o', linewidth=2)
        ax1.plot(rounds, test_loss, label='Test Loss (To√†n c·ª•c)',
                 marker='s', linewidth=2)
        ax1.set_xlabel('Round', fontweight='bold')
        ax1.set_ylabel('Loss', fontweight='bold')
        ax1.set_title('Train Loss & Test Loss', fontweight='bold', fontsize=14)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_xticks(rounds)

        ax2 = axes[1]
        test_acc_pct = [acc * 100 for acc in test_acc]
        ax2.plot(rounds, test_acc_pct, label='Test Accuracy (%)',
                 marker='o', linewidth=2, color='green')
        ax2.set_xlabel('Round', fontweight='bold')
        ax2.set_ylabel('Accuracy (%)', fontweight='bold')
        ax2.set_title('ƒê·ªô ch√≠nh x√°c tr√™n Test Set To√†n c·ª•c', fontweight='bold', fontsize=14)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 100])
        ax2.set_xticks(rounds)

        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì l·ªãch s·ª≠ hu·∫•n luy·ªán t·∫°i: {save_path}")
        plt.show()

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    finally:
        plt.close()
        print("="*80)


def evaluate_and_save_results(server, history, config, output_dir, data_stats, training_duration, start_time, end_time):
    """
    ƒê√°nh gi√° cu·ªëi c√πng, l∆∞u model, history, config v√† t·∫°o c√°c b√°o c√°o.
    """
    print("\n" + "="*80)
    print("üíæ B∆Ø·ªöC 9 & 10: ƒê√ÅNH GI√Å CU·ªêI C√ôNG V√Ä L∆ØU K·∫æT QU·∫¢")
    print("="*80)

    model_path = os.path.join(output_dir, 'global_model.pth')
    torch.save(server.global_model.state_dict(), model_path)
    print(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh to√†n c·ª•c: {model_path}")

    history_path = os.path.join(output_dir, 'training_history.pkl')
    with open(history_path, 'wb') as f:
        pickle.dump(history, f)
    print(f"‚úÖ ƒê√£ l∆∞u l·ªãch s·ª≠ hu·∫•n luy·ªán: {history_path}")

    config_path = os.path.join(output_dir, 'config.json')
    config_to_save = config.copy()
    config_to_save['device'] = str(config['device'])
    with open(config_path, 'w') as f:
        json.dump(config_to_save, f, indent=2)
    print(f"‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh: {config_path}")

    stats_path = os.path.join(output_dir, 'data_statistics.json')
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(data_stats, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ ƒê√£ l∆∞u th·ªëng k√™ d·ªØ li·ªáu: {stats_path}")

    plot_path = os.path.join(output_dir, 'training_history.png')
    plot_training_history(history, plot_path)

    print("\n‚Üí ƒêang t·∫°o d·ª± ƒëo√°n (predictions) tr√™n Test Set to√†n c·ª•c...")
    all_y_true = []
    all_y_pred = []
    server.global_model.eval()

    for loader_idx, loader in enumerate(server.client_test_loaders):
        pbar = tqdm(
            loader,
            desc=f"[Predict] Client TestLoader {loader_idx}",
            unit="batch",
            leave=False
        )
        with torch.no_grad():
            for data, target in pbar:
                data, target = data.to(server.device), target.to(server.device)
                output = server.global_model(data)
                pred = output.argmax(dim=1)

                all_y_true.append(target.cpu().numpy())
                all_y_pred.append(pred.cpu().numpy())

    y_true = np.concatenate(all_y_true)
    y_pred = np.concatenate(all_y_pred)
    print("‚úÖ ƒê√£ t·∫°o d·ª± ƒëo√°n xong.")

    print("\n" + "="*80)
    print("üìÑ CLASSIFICATION REPORT")
    print("="*80)
    class_labels = [str(i) for i in range(config['num_classes'])]
    report = classification_report(
        y_true,
        y_pred,
        labels=range(config['num_classes']),
        target_names=class_labels,
        zero_division=0,
        digits=4
    )
    print(report)

    report_path = os.path.join(output_dir, "classification_report.txt")
    with open(report_path, 'w') as f:
        f.write("CLASSIFICATION REPORT\n" + "="*80 + "\n\n" + report)
    print(f"\nüíæ ƒê√£ l∆∞u report: {report_path}")

    print("\n‚Üí ƒêang t·∫°o ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)...")
    cm = confusion_matrix(y_true, y_pred, labels=range(config['num_classes']))

    show_labels = (config['num_classes'] <= 40)
    fig_size = max(12, config['num_classes'] * 0.4)
    plt.figure(figsize=(fig_size, fig_size * 0.8))

    sns.heatmap(
        cm,
        annot=show_labels,
        fmt='d',
        cmap='Blues',
        cbar=True,
        xticklabels=class_labels if show_labels else False,
        yticklabels=class_labels if show_labels else False
    )

    final_test_accuracy = history['test_accuracy'][-1]

    plt.title(f'Confusion Matrix - Final Global Model\n'
              f'Test Accuracy: {final_test_accuracy:.4f} ({final_test_accuracy*100:.2f}%)',
              fontsize=14, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)

    if show_labels:
        plt.xticks(rotation=90)
        plt.yticks(rotation=0)

    plt.tight_layout()
    cm_path = os.path.join(output_dir, "confusion_matrix.png")
    plt.savefig(cm_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ ƒê√£ l∆∞u confusion matrix: {cm_path}")
    plt.show()
    plt.close()

    print("\n‚Üí ƒêang l∆∞u metrics chi ti·∫øt (F1, Precision, Recall)...")
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true,
        y_pred,
        labels=range(config['num_classes']),
        average=None,
        zero_division=0
    )
    detailed_metrics = {
        'class': class_labels,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'support': support
    }
    df_metrics = pd.DataFrame(detailed_metrics)
    csv_path = os.path.join(output_dir, "detailed_metrics.csv")
    df_metrics.to_csv(csv_path, index=False)
    print(f"‚úÖ ƒê√£ l∆∞u detailed metrics: {csv_path}")

    print("\n" + "="*80)
    print("üìä TOP 5 CLASSES PERFORMANCE:")
    print("="*80)
    df_sorted = df_metrics.sort_values('f1_score', ascending=False)
    print("\nTop 5 Best Classes (by F1-score):")
    print(df_sorted.head(5).to_string(index=False))
    print("\nTop 5 Worst Classes (by F1-score):")
    print(df_sorted.tail(5).to_string(index=False))
    print("="*80)

    print("\n" + "="*80)
    print("üìù B∆Ø·ªöC 10: T·∫†O SUMMARY REPORT")
    print("="*80)
    summary_path = os.path.join(OUTPUT_DIR, "SUMMARY_REPORT.txt")
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n" + " " * 20 + "FEDERATED LEARNING SUMMARY REPORT\n" +
                "="*80 + "\n\n")
        f.write("üìÖ TH·ªúI GIAN:\n")
        f.write(f"  ‚Ä¢ B·∫Øt ƒë·∫ßu: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"  ‚Ä¢ K·∫øt th√∫c: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"  ‚Ä¢ T·ªïng th·ªùi gian: {training_duration:.2f}s ({training_duration/60:.2f} ph√∫t)\n\n")
        f.write("‚öôÔ∏è  C·∫§U H√åNH:\n")
        f.write(f"  ‚Ä¢ Chi·∫øn l∆∞·ª£c: {config['algorithm'].upper()}\n")
        if config['algorithm'] == 'fedprox':
            f.write(f"  ‚Ä¢ Mu (proximal): {config['mu']}\n")
        f.write(f"  ‚Ä¢ S·ªë clients: {config['num_clients']}\n")
        f.write(f"  ‚Ä¢ S·ªë rounds: {config['num_rounds']}\n")
        f.write(f"  ‚Ä¢ Epochs/round: {config['local_epochs']}\n")
        f.write(f"  ‚Ä¢ Batch size: {config['batch_size']}\n")
        f.write(f"  ‚Ä¢ Learning rate: {config['learning_rate']}\n")
        f.write(f"  ‚Ä¢ Input features: {config['input_shape'][0]}\n")
        f.write(f"  ‚Ä¢ Num classes: {config['num_classes']}\n")
        f.write(f"  ‚Ä¢ Ch·∫°y song song: {config['use_multiprocessing']}\n")

        f.write("\nüìä K·∫æT QU·∫¢ CU·ªêI C√ôNG (T·ªîNG H·ª¢P T·ª™ TEST SET):\n")
        if history['test_accuracy']:
            final_acc = history['test_accuracy'][-1]
            final_loss = history['test_loss'][-1]
            f.write(f"  ‚Ä¢ Final Test Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\n")
            f.write(f"  ‚Ä¢ Final Test Loss: {final_loss:.4f}\n")

        f.write("\nüìÅ OUTPUT FILES:\n")
        f.write(f"  ‚Ä¢ Th∆∞ m·ª•c: {OUTPUT_DIR}\n")
        f.write(f"  ‚Ä¢ Model: global_model.pth\n")
        f.write(f"  ‚Ä¢ History: training_history.pkl\n")
        f.write(f"  ‚Ä¢ Plots: training_history.png\n")
        f.write(f"  ‚Ä¢ Report: classification_report.txt\n")
        f.write(f"  ‚Ä¢ Metrics: detailed_metrics.csv\n")
        f.write(f"  ‚Ä¢ Config: config.json\n")

        f.write("\n" + "="*80 + "\n" + "‚úÖ HU·∫§N LUY·ªÜN TH√ÄNH C√îNG!\n" + "="*80 + "\n")

    print(f"‚úÖ ƒê√£ t·∫°o summary report: {summary_path}")


# ============================================================================
# üí° B∆Ø·ªöC 11: H√ÄM MAIN üí°
# ============================================================================

def main():
    # ============================================================================
    # üîß THI·∫æT L·∫¨P MULTIPROCESSING CHO CUDA
    # ============================================================================
    # QUAN TR·ªåNG: V·ªõi CUDA, PH·∫¢I d√πng 'spawn' method ƒë·ªÉ tr√°nh l·ªói:
    # "Cannot re-initialize CUDA in forked subprocess"
    #
    # L∆∞u √Ω khi ch·∫°y trong Jupyter notebook:
    # - Spawn c√≥ th·ªÉ g√¢y pickle error v√¨ worker kh√¥ng import ƒë∆∞·ª£c __main__
    # - N√™n ch·∫°y script n√†y nh∆∞ file .py thay v√¨ trong notebook:
    #   $ python run_federated_training.py

    # Ki·ªÉm tra xem c√≥ ƒëang ch·∫°y trong notebook kh√¥ng
    try:
        from IPython import get_ipython
        if get_ipython() is not None and 'IPKernelApp' in get_ipython().config:
            in_notebook = True
            print("‚ö†Ô∏è  C·∫¢NH B√ÅO: ƒêang ch·∫°y trong Jupyter notebook!")
            print("   Multiprocessing v·ªõi CUDA trong notebook c√≥ th·ªÉ g·∫∑p v·∫•n ƒë·ªÅ.")
            print("   Khuy·∫øn ngh·ªã: Ch·∫°y script nh∆∞ file .py ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t:")
            print("   $ python run_federated_training.py\n")
        else:
            in_notebook = False
    except:
        in_notebook = False

    # Set spawn method CHO CUDA (b·∫Øt bu·ªôc ƒë·ªÉ tr√°nh fork issues)
    current_method = mp.get_start_method(allow_none=True)
    if current_method != 'spawn':
        try:
            mp.set_start_method('spawn', force=True)
            print(f"‚úÖ ƒê√£ thi·∫øt l·∫≠p multiprocessing method: 'spawn' (required for CUDA)")
        except RuntimeError:
            print(f"‚ÑπÔ∏è  Multiprocessing method: {mp.get_start_method()}")
    else:
        print(f"‚ÑπÔ∏è  Multiprocessing method: spawn (already set)")

    config = CONFIG
    start_time = datetime.now()

    print("="*80)
    print("ü§ñ FEDERATED LEARNING V·ªöI M√î H√åNH CNN-GRU (IoT IDS)")
    print("="*80)

    try:
        device = check_and_setup_gpu(config)
        config['device'] = device

        input_shape, num_classes, data_stats = auto_detect_data_parameters(
            data_dir=config['data_dir'],
            num_clients=config['num_clients']
        )
        config['input_shape'] = input_shape
        config['num_classes'] = num_classes

        print("\n" + "="*80)
        print("‚öôÔ∏è  C·∫§U H√åNH CU·ªêI C√ôNG")
        print("="*80)
        print(json.dumps(config, indent=2, default=str))
        print("="*80)

        train_loaders, test_loaders = load_federated_data(
            data_dir=config['data_dir'],
            num_clients=config['num_clients'],
            batch_size=config['batch_size'],
            device=config['device']
        )

        server, clients = initialize_federated_system(
            train_loaders=train_loaders,
            test_loaders=test_loaders,
            input_shape=config['input_shape'],
            num_classes=config['num_classes'],
            device=config['device']
        )

        history = train_federated(server, config, train_loaders)

        end_time = datetime.now()
        training_duration = (end_time - start_time).total_seconds()

        print("\n" + "="*80)
        print("üèÅ HU·∫§N LUY·ªÜN HO√ÄN T·∫§T!")
        print("="*80)
        print(f"‚è±Ô∏è  Th·ªùi gian hu·∫•n luy·ªán: {training_duration:.2f} gi√¢y ({training_duration/60:.2f} ph√∫t)")

        evaluate_and_save_results(
            server, history, config,
            config['output_dir'], data_stats,
            training_duration, start_time, end_time
        )

        print("\n" + "="*80)
        print("üéâ üéâ üéâ  HO√ÄN T·∫§T T·∫§T C·∫¢ C√ÅC B∆Ø·ªöC  üéâ üéâ üéâ")
        print("="*80)

    except Exception as e:
        logger.error("\n‚ùå ƒê√É X·∫¢Y RA L·ªñI TRONG QU√Å TR√åNH CH·∫†Y SCRIPT")
        logger.error(f"Chi ti·∫øt l·ªói: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
